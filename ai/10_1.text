----------------------------------------------------------------------
10. 인공지능의 핵심기술, 머신러닝
----------------------------------------------------------------------

[1 페이지]
구글의 딥마인드팀은 컴퓨터에게 아타리 게임을 할 수 있도록 학습시켰습니다.
컴퓨터는 이 게임을 배우거나 프로그램화되지 않았습니다.
그 대신에 점수를 기록함과 동시에 키보드의 움직임을 관찰하게 하였고 목표는 점수를 최대화시키는 것이었습니다.
처음에는 모든 행동들이 랜덤하였지만 2시간이 지난 후 컴퓨터는 아타리 게임의 전문가가 되었습니다.
4시간 후 컴퓨터는 스스로 아타리 게임에 있어 가장 효율적인 tunnel을 뚫고 벽돌을 깨는 방법을 터득하였습니다.

아타리 게임을 배우는 딥마인드의 학습 속도는 우리의 상상을 초월합니다.
딥마인드의 알파고는 복잡한 게임인 바둑에서 인간을 앞선 것처럼 말입니다.





----------------------------------------------------------------------
10_02 머신러닝 개요
----------------------------------------------------------------------

[2 페이지]
우리는 지금까지 다양한 유형의 인공지능 기술에 대해 함께 학습하셨습니다.

그러한 기술들을 하나의 다이어그램으로 나타내면 이렇게 표현이 될 텐데요.
밑에서부터 한번 살펴볼까요?

제일 밑단에 있는 것이 바로 Robotics 기술입니다.
이것은 로봇과 테크닉스의 결합으로서 로봇에 다양한 센서나 인공지능을 달아서 로봇의 기능을 향상하는 그런 분야입니다.

바로 위에 있는 것이 Planning이지요.
이것은 인공지능을 이용해서 최적화된 절차나 계획을 수립하는 분야고요.

그 위에 있는 것이 바로 Speech입니다.
이것에 대해서는 앞서 인공지능 스피커와 관련해서 설명을 드렸는데 Speech를 텍스트로 변환하는 기술, 반대로 텍스트를 Speech로 변환하는 기술이 바로 인공지능 분야와 관련된 기술이 되겠습니다.

네 번째는 Vision, 시각화 기술로서 이러한 다양한 사물들을 인식해서 이 사물이 무엇인지 확인하는 그런 기술과 이러한 기술을 기반으로 한 머신비전이 현재 스마트 팩토리를 비롯한 다양한 제조 생산 라인에서 활용이 되고 있지요.

또 다음으로 제2의 인공지능의 중흥기를 열었던 Expert systems, 즉 전문가 시스템에 대한 연구도 지금 현재 활발하게 이루어지고 있습니다.

바로 윗단에 가보시면 NLP가 나오지요.
Natural Language Processing 해서 이것은 자연화를 처리해서 기계가 자연화를 이해하고 이해한 단어를 기반으로 해서 무엇인가 새로운 가치 정보를 표시하고 표출하는 활동인데요.
그와 관련해서는 콘텐츠를 추출하는 기술, 다양한 단어들을 유사한 단어끼리 분리하는 기술 그리고 기계가 이런 것들을 직접 번역해주는 기계 번역 기술이 여기에 해당하며 우리가 올린 질문에 대해서 자동으로 대답해주는 Question answering 기술 그리고 기계가 알아서 새로운 텍스트를 생성해주는 Text generation 기술들이 여기에 해당합니다.

이러한 분류에 가장 상단에 위치하는 Machine learning과 관련해서는 크게 Deep learning 그다음에 Supervised learning, Unsupervised learning 이렇게 분류하고 있는데요.
오늘 수업에서는 맨 위 상단에 있는 Machine learning 기술 중 지도 학습과 비지도 학습에 대해서 중점적으로 학습을 하시겠습니다.

게임 회사들은 인공지능 기술을 게임을 개발하는데 적용을 하고자 다양한 시도를 하고 있습니다.
만약 게임을 개발하기 위해서 게임 엔진을 사용하는 대신에 인공지능을 이용해서 인공지능 스스로가 게임 스테이지를 만들어낸다면 어떨까요?

여러분 중에는 나이가 조금 있는 분들 그리고 옛날 게임에 푹 빠진 분들은 너구리라는 게임을 아마 아실 것입니다.
너구리는 몇 개 층을 왔다 갔다 하면서 당근, 앵두, 버섯, 단감 등 채소와 과일을 먹는 게임인데요.
중간에 지뢰를 밟거나 채소와 과일을 지키는 쥐한테 잡히거나 물동이를 깼을 때 거기서 나오는 뱀한테 물리면 바로 죽는 게임입니다.
너구리가 이런 세 가지의 장애 요소를 피해서 마지막 스테이지에 이르면 그것이 바로 맥주인데요.
그런데 맥주를 깨면 또 맥주 스테이지가 나오고 그 판을 깨면 또 맥주 스테이지 이렇게 끝없이 맥주 스테이지만 반복됩니다.
아마도 계속 새로운 판을 만들려면 개발자가 직접 프로그래밍을 해야 하는데 이를 위해서는 시간과 돈이 들어가니까 그냥 맥주판을 적당히 어렵게 만들어서 20개의 스테이지로 끝낸 것 같습니다.

그런데 GPU를 생산하는 기업인 NVIDIA가 2020년 초 팩맨 출시 40주년을 기념해서 자사의 인공지능 모델로 팩맨을 재현한 일이 있었습니다.
딥러닝 기술의 일종인 생성적 대립 신경망, 즉 GAN을 탑재해 인공지능 스스로 게임을 하면서 게임을 재현했는데요.

이를 위해 인공지능은 5만 회에 달하는 팩맨의 원본 게임의 플레이 영상을 학습했다고 합니다.
인공지능은 장면을 이동할 때 보이는 아주 미묘한 섬세한 그런 차이점들을 하나하나 기억하고 동일한 규칙이 작용되는 새로운 게임을 스스로 만들어냈는데요.
이러면 새로운 판이 네버엔딩으로 전개가 되겠지요.
어쩌면 우리는 죽을 때까지 마지막 판을 깨지 못할지도 모르겠습니다.
앞으로는 게임 엔진을 만드는 대신에 인공지능을 이용해서 새로운 스테이지를 만나는 일이 가능해질 것으로 생각됩니다.

앞서 인공지능이 만든 게임 사례를 말씀을 드렸는데 사실은 인공지능으로 게임을 개발하기보다는 게임을 이용해서 인공지능을 학습시키는 것이 더 일반적입니다.
이번 수업에서 수도 없이 언급한 알파고 또한 바둑 게임을 이용해서 성장한 인공지능 프로그램 중 하나입니다.

딥마인드는 특정 분야에서 반복 학습을 통해 성장 알고리즘을 연구했는데요.
여기에 이용된 알고리즘이 바로 DQN입니다.

DQN은 Deep Q-Network의 약자로 인공지능이 스스로 게임을 하면서 고득점을 내도록 고안된 학습 알고리즘이지요.
구글 딥마인드는 DQN 연구를 통해서 아타리 2600을 이용했습니다.
이 게임은 아타리사에서 1997년도에 만든 콘솔 게임으로 정말 고전 중의 고전으로 꼽히는데요.
이 게임의 알고리즘은 상당히 심플합니다.
개발자는 DQN에게 반복 학습을 시켜서 스스로 게임 방식을 터득하도록 했는데 DQN은 무수한 시행착오를 겪으면서 게임에 적응하게 되었고 결국 인간이 기록한 최고 점수를 시원하게 갈아치웠습니다.

이처럼 DQN은 게임을 통해 성장하였고 이러한 알고리즘은 바로 알파고의 바탕이 되었습니다.

이제 다시 머신러닝으로 돌아와 볼까요?
머신러닝은 컴퓨터가 주어진 정보의 규칙을 분석하도록 하고, 새로운 정보가 주어졌을 때 그 규칙을 기반으로 결과 값을 예측하는 기술입니다.

즉 머신러닝은 무언가를 프로그래밍 하는 것이 아니라 데이터로부터 학습을 해서 학습을 수행하는 방법을, 즉 작업을 수행하는 방법을 컴퓨터에게 가르치는 것이지요.
머신러닝이란 말을 처음 사용한 아서 사무엘은 머신러닝을 다음과 같이 정의한 바 있습니다.
1952년 아서 사무엘은 체커라는 게임을 개발했는데요.
체커는 최초의 머신러닝 프로그램으로 경험으로부터 학습하는 방법을 사용했으며 인공지능 개발의 바탕이 되었습니다.

아서 사무엘을 포함한 머신러닝 분야의 위대한 선지자들과 그들의 업적을 정리하면 다음과 같습니다.
표를 보셨는데요.
대부분 지난 강의에서 다 언급한 내용들이었습니다.
SVM도 지난 9차시 강의에서 학습한 내용이지요.
서포트 벡터 머신, 즉 SVM은 새로운 데이터가 어느 영역에 속하는지 판단하는 이용되는 머신러닝 모델로서 가장 큰 폭을 가진 하나의 경계선을 찾는 것이 매우 중요하다고 말씀을 드렸습니다.

즉 영역의 여백, 마진이 최대가 되는 그런 중심선을 찾는 것이 모델의 정확도와 비례하기 때문에 그 중심선을 정확하게 찾아야 한다고 그렇게 말씀을 드린 바가 있었습니다.
예전에는 이 경계선을 인간이 직접 찾아줘야 했지만 머신러닝의 등장으로 컴퓨터가 알아서 이 경계선을 찾아주고 있습니다.

이러한 머신러닝은 다음과 같은 공통적인 특징을 가집니다.
첫 번째, 스스로 데이터에서 규칙이나 지식을 추출한다는 점.
두 번째, 코딩이 아닌 예제를 통해서 학습을 한다는 점.
세 번째, 프로그래밍이 어려운 작업을 해결하는데 주로 활용이 된다는 점입니다.

현재 머신러닝은 이미지처리, 영상인식, 음성인식, 인터넷 검색 등 다양한 분야에 활용이 되고 있습니다.
머신러닝 기술이 적용된 분야로는 채팅봇이라든가 자율주행 자동차, 주가예측 등 굉장히 많은 분야에 적용이 되고 있는데 특히 예측에 있어서 탁월한 성과를 나타내고 있습니다.
우리가 앞서 학습한 구글의 자율주행 자동차, 아마존과 넷플릭스에서 제공하는 추천 서비스, 금융 거래에서 부당 거래를 탐지하는 사기 탐지 모두 머신러닝을 통해서 그 기능을 점점 고도화 시켜 나가고 있습니다.

그러면 다음에서는 머신러닝을 활용한 기업 사례를 신문 기사를 통해 함께 살펴보시겠습니다.

A 백화점은 고객 컴플레인에서 추출한 데이터를 현업에 활용하는 VOC 데이터 랩 시스템 개발을 완료하였습니다.
비정형 텍스트 데이터를 정제해 경영에 활용하는 것으로서 시각 기법을 활용해 데이터를 직관화 하고 위협어 감지와 신규 불만 접수 알림 기능을 탑재해 업무 활용도를 높였습니다.
특히 중복 접수된 고객 불만은 실시간 검색어 순위처럼 표현됩니다.
고객 불만 글의 핵심과 의도를 자동으로 파악하고 그래서 나타나는 여러 의미를 통계적으로 분석해 현장 업무 개선에 필요한 메시지를 추출하는 것이 핵심입니다.
기존 VOC 시스템은 전국 점포와 온라인을 통해 접수된 불만과 제안 등 연간 2만 건 이상들이 등록되었으나 텍스트 형태로 저장된 민원 대부분이 형식과 내용이 제각각인 비정형 데이터로 이를 체계적으로 활용하는 데는 한계가 있었습니다.
그래서 민원 글을 분석하는 텍스트 분석 TA를 통해 고객 반응과 관심사를 유관부서에 효과적으로 전달하는데 중점을 두게 되고 VOC 분석 시스템 도입으로 감정 지수 평가, 핵심 키워드 추출, 의미연결, 중요도 계산, 시각적 공유, 통합 검색 등 모든 과정을 AI가 대체하게 되었습니다.

기사 내용을 보시면 고객을 불만을 처리하는 VOC 시스템에 인공지능 기술을 입혀서 경영성과의 향상을 기대한다는 내용인데요.
그렇다면 인공지능 기술을 적용하면 어떤 가치가 있을까요? 과거에는 각 점포 별로 취합된 고객의 소리, 즉 VOC를 수작업으로 분류를 해야만 했습니다.

그런데 이 과정에서 담당자의 주관이 개입될 수도 있고 또 담당자의 실수로 고객의 컴플레인이 잘못 분류되기도 했는데요.
하루에 접수되는 VOC가 워낙 많기 때문에 자료를 처리하는 정확도와 생산성이 모두 낮을 수밖에 없었던 것이지요.

그런데 지금은 VOC가 과거와는 비교가 안 될 정도로 많이 양산이 되고 있습니다.
예전에는 게시판에 글 하나 쓰려면 PC에 접속해서 아이디, 패스워드 넣고 게시판을 찾아가서 직접 글을 남겨야 했는데 지금은 스마트폰에 깔린 앱을 클릭하면 자동 로그인이 되어서 고객의 의견을 쉽게 입력할 수 있는 환경이 되었지요.
또한 고객들은 자신의 불만을 SNS 여기저기에 마구 퍼트리고 다닙니다.
요즘 소비자가 어디 보통 소비자입니까?
그렇다 보니 사람이 수동으로 처리할 수 있는 업무량을 훌쩍 넘어선 것이지요.

이 문제를 해결하기 위해서 이 회사는 인공지능을 투입한 것입니다.
수만 개의 컴플레인을 인공지능이 정확하게 리얼 타임으로 집계를 해주면
첫째, 고객의 불만을 즉각적으로 파악해서 빠른 개선이 가능해지고요.
두 번째, 고객의 목소리가 영업부서, 마케팅부서, 상품기획 등 다양한 부서에 유용한 정보로 사용이 될 수 있습니다.
세 번째, 시각화를 통해서 어디서 문제가 발생했고 그 문제가 현재 어떻게 처리되고 있는지 담당자가 한눈에 볼 수 있게 지원합니다.

여러분이 차를 몰고 가다 보면 어제 교통사고를 통해서 몇 명이 사망했고 몇 명이 부상인지 이런 것들을 보여주는 집계 판을 보실 수 있을 것입니다.
이를 통해 우리는 안전운전을 해야겠다는 경각심을 갖게 되지요.
이와 같은 원리로 전국 매장에서 발생하는 VOC를 실시간으로 분석해서 고객들이 주로 어떤 건으로 컴플레인을 제기하고 현재 어떻게 처리되고 있는지 이러한 컴플레인이 증가하는지 감소하는지 실시간으로 분석하고 이를 시각화해서 직관적으로 보여준다면 기업이 컴플레인을 줄이는데 분명히 도움이 될 것입니다.

이것이 바로 VOC 분석에 인공지능을 도입해서 얻을 수 있는 혜택이자 가치가 되겠지요.
이러한 분석을 지원하는 기술 중 하나가 바로 Word2Vec이라는 기술이 있습니다.
Word2Vec이란 단어의 의미를 벡터로 변환해서 컴퓨터가 분석할 수 있도록 하는 기술인데요.
단어의 의미를 파악하고 단어 간의 유사성을 찾기 위해 말뭉치를 입력받아서 이것을 벡터로 표현하는 그런 것들을 분석해주는 기술입니다.

여기서 말뭉치란 언어 연구를 위해서 컴퓨터가 텍스트를 가공, 처리, 분석할 수 있는 형태로 모아 놓은 자료의 집합을 말합니다.
예를 들어 보겠습니다.
제가 문장을 하나 들어보겠는데요.
‘나는 어제 11번지에서 마사지 건을 샀는데 조립하기가 너무 힘들어서 결국 조립을 못 했다.’
과거에는 이런 VOC가 접수가 되면 내용을 전산에 입력하기 위해서 마사지 건, 조립, 불만 이런 식으로 일일이 엑셀에 하나하나 입력해야 했습니다.
그런데 지금은 인공지능 알고리즘을 이용해서 조금 더 쉽고 정확하게 분석할 수 있게 된 것이지요.

고객의 불만 글과 같은 비정형 데이터를 분석하기 위해서는 우리가 Word2Vec을 이용할 수 있는데 어디서, 어떤 상황에서 고객의 불만이 극대화되었는지 알 수 있게 합니다.
또한 Word2Vec과 같은 도구와 시각화 라이브러리를 조합하면 이러한 정보들을 그래픽으로 이용해 보다 직관적으로 전달할 수 있습니다.

Word2Vec을 이용한 VOC 분석사례를 한번 보시겠습니다.

보통 고객의 소리를 분석하면 그 안에는 칭찬 글과 비판 글이 함께 들어가 있거든요.
이 마사지 건과 관련해서 긍정적인 글들을 한번 분석해봤더니 큰 키워드로 유재선과 가격이라는 것이 나옵니다.
이런 유재선이라는 정보에 뛰는 사람과 TV가 붙었는데 우리 이를 통해서 유추할 수 있는 것은 유재선 씨가 TV 프로그램인 뛰는 사람에 나온 마사지 건을 보고 사람들이 샀다는 것을 알 수 있습니다.
즉 유재선 씨는 마사지 건을 홍보하는 매우 완벽한, 훌륭한 홍보 채널이 되는 것이지요.
이를 통해 보면 이 마사지 건 사에서 유재선이라는 사람을 모델로서 잘 썼다고 또 뛰는 사람이라는 프로그램에 PPL로 넣기를 잘했다는 것을 일차적으로 확인할 수 있습니다.

두 번째 긍정적인 데이터를 보니까 가격이라는 키워드가 나오고요.
연관 단어로 인터넷과 BLICK이라는 것이 나옵니다.
아마도 이 마사지 건은 인터넷에서 가격 경쟁력이 있는 것 같고 유사 제품, 경쟁사의 제품인 BLICK에 비해서 훨씬 더 가격이 낮다는 점이 고객이 인지하는 장점으로 인지가 됩니다.
이를 통해서 볼 때 고객의 VOC를 분석했더니 우리가 광고, 홍보를 잘하고 있구나.
그다음에 경쟁사의 제품에 비해서 우리가 가격적인 메리트가 있다는 것을 쉽게 알 수 있지요.

무엇을 통해?
고객의 소리를 통해.
다음으로 본격적으로 불만의 소리로 한번 가보도록 하겠습니다.

A 마사지 건과 관련해서 발견되는 가장 큰 문제점으로는 소음, 조립, 파손 문제가 제시되었는데요. 먼저 소음을 살펴봤더니 소음과 관련된 단어로 불량과 환불이 가장 크게 나왔습니다.
이런 세 가지의 단어를 우리가 유추해볼 때 이 마사지 건은 소음이 너무 커서 불량 같이 느끼는 경우도 있다는 것입니다.
그러니까 정상 제품임에도 불구하고 소음이 크기 때문에 고객들이 이 제품을 불량으로 인지하고 제품을 환불해달라는 VOC가 많다는 것을 알 수 있었고요.
두 번째로 건너가서 조립과 관련된 문제를 보면 고소, 상처, 중단, 매뉴얼 이런 것들이 나오는데요.
이러한 단어를 통해 볼 때 조립하기 위해서 매뉴얼이 너무 정보가 불충분하거나 복잡하다는 것을 알 수 있고 조립하기가 너무 힘들어서 조립을 몇 번 하다가 중단해서 고객들이 열 받아 있다는 것을 알 수 있습니다.
게다가 조립하다가 상처가 나서 나는 이 제품을 고소하겠다.
이런 극단적인 VOC도 보이네요.

이를 통해서 볼 때 이 자사의 제품과 관련해서 소음을 최소화하고 조립상 프로세스를 쉽게 하기 위해서 어떻게 매뉴얼을 주고 또 조립을 도와주는 도구를 어떻게 제공할 건지 이런 것들에 대한 통찰력을 얻을 수 있을 것 같습니다.

A 마사지 건과 관련해서 발생하는 세 번째 키워드 바로 파손인데요.
파손과 관련된 키워드로는 AS, 환불, 교환, 한 달 이런 단어가 제일 많이 나왔습니다.
이런 단어로 유추해볼 때 파손이 가장 많이 일어나는 기간은 한 달 내인 것 같아요. 한 달 내 파손이 이루어졌기 때문에 이것에 대해서 교환을 해 달라, 환불을 해 달라, AS를 해 달라 이런 요청이 많은데 이런 세 가지 요청 중 가장 많이 사이즈가 큰 단어가 바로 환불이지요.
이를 통해 볼 때 한 달 내 제품이 파손됐을 때 대부분의 고객들은 환불을 원하고 그다음으로는 교환과 AS를 원한다는 것을 알 수 있었습니다.
이것은 고객으로부터 접수된 적게는 몇 백 개, 많게는 몇 만 개의 데이터를 Word2Vec으로 분석해서 이 제품과 관련된 장점은 무엇이고 이 제품과 관련된 고객의 불만은 무엇인지 분석한 다음에 이런 것들을 우리가 쉽게 이해할 수 있도록 어떤 시각화 도구를 통해서 직관적으로 제시한 사례인데요.

이런 데이터를 보면 마케팅팀에서 그다음에 개발부서에서 어떤 것들은 강점으로 가져가고 어떤 것들은 보완해야 할지를 쉽게 알려준다는 측면에서 도움이 되는 분석 결과라고 말씀을 드릴 수 있겠습니다.

다음은 머신러닝의 작동 방식입니다.
워낙 앞부분에서 이 부분에 대해서 반복적으로 설명을 드렸는데 다시 한번 정리를 할게요.
머신러닝의 작동 방식은 다음과 같습니다.
먼저 컴퓨터를 학습시키기 위해서 개와 고양이의 이미지를 제공하면 컴퓨터는 이들 이미지의 특성을 파악해서 개와 고양이의 형태를 학습합니다.
그런 후에 주어지는 이미지를 분석해서 그것이 개인지, 고양인지 파악하고 컴퓨터 스스로가 개와 고양이를 분류해서 결과를 제시하는 방식인데요.

그렇다면 컴퓨터를 활용한 정보 처리와 머신러닝은 어떤 차이점이 있을까요?
컴퓨터를 활용해서 일을 처리하기 위해서는 인간이 컴퓨터에게 일을 처리하는 방법과 규칙을 알려줘야 합니다.
이것이 바로 프로그래밍이며 이를 통해 컴퓨터는 인간에게 결과 값을 알려주게 됩니다.

그러나 머신러닝은 컴퓨터에게 처리 방법을 지시하지 않습니다.
대신 인간이 원하는 결과를 알려주면 컴퓨터는 데이터를 원하는 결과로 바꾸는 처리 방법을 스스로 만들며 그 방법대로 결과 값을 도출해서 인간에게 알려줍니다.
이것이 어떻게 과연 가능할까요?
컴퓨터가 데이터를 분석하고 스스로 학습하는 과정을 거치면 어느 정도의 패턴을 인식할 수 있게 되며 입력하지 않은 정보에 대해서도 컴퓨터가 이 패턴을 기반으로 해서 스스로 판단을 할 수 있게 됩니다.

이처럼 머신러닝의 핵심은 데이터 기반 학습으로 고품질의 데이터가 많으면 좋은 성능을 낼 수 있고 머신러닝에 결과가 쌓이면 객체를 식별하는 정확도도 높아지게 됩니다.
그러면 머신러닝에서의 학습은 무엇을 의미할까요?
조금 더 실무적인 관점에서의 학습은 표현, 평가 그리고 최적화를 말합니다.
이러한 세 가지 프로세스가 진행이 되면 학습이 이루어졌다고 볼 수 있는 것이지요.

다음에서는 표현, 평가, 최적화에 대해서 설명을 드리겠습니다.

먼저 표현은 어떤 업무를 수행하는 Agent가 입력 값을 처리해서 어떻게 결과 값을 만드는지 결정하는 것입니다.
다음으로 평가는 Agent가 얼마큼 업무를 잘 수행했는지 판단하는 활동이고요.
마지막으로 최적화는 평가에서 설정한 기준을 최적으로 만족시키는 조건을 찾는 것으로 최적화 과정이 끝나면 학습 모델에 사용된 가중치가 결정됩니다.
가중치가 결정이 되면 학습이 완료된 것이며 이러한 모델을 통해 새로운 데이터에 대해 예측을 할 수 있게 되는데 우리는 이것을 일반화라고 부릅니다.

다음 사례를 통해서 표현, 평가, 최적화, 일반화를 설명해 보도록 하겠습니다.
컴퓨터에 필기체를 인식시키는 학습을 하는 이것을 시켜보는 상황을 한번 가정해 보겠습니다.
화면에서 보시는 바와 같이 너무나 다양한 글씨체가 있지요.
이 글씨를 보고 컴퓨터가 숫자를 판독하도록 학습을 시켜야 합니다.
‘얘들아, 인간은 2를 이렇게 다양하게 쓴단다.’
어떠한 악필도 정확하게 알아내도록 하는 것이 바로 학습의 목표가 됩니다.
이때 표현은 사람이 쓴 숫자가 어떤 숫자를 의미하는지 인식하고 분류하는 논리 모형으로 다음과 같은 모델이 표현에 해당합니다.
이렇게 만들어진 모형으로 학습을 시킨 후에 컴퓨터에게 사람이 적은 숫자를 보여줬습니다.
우리가 보여준 숫자의 데이터 값은 9였는데요.
컴퓨터는 이것을 4라고 예측합니다. 틀렸지요?
그런데 사실 누가 이것을 9라고 보겠습니까?
하지만 9를 이렇게 쓰는 사람이 있기 때문에 컴퓨터가 이런 예외 상황까지 정확하게 인지할 수 있도록 부단히 학습을 시켜야 하는 것이지요.

즉 논리모형을 정교화 시켜야 한다는 것입니다.
이처럼 평가는 Agent가 얼마큼 업무를 잘 수행했는지 판단하는 활동으로 컴퓨터가 필기체를 인식하는 훈련을 받고 필기체를 정확히 식별하는 확률로 설명이 될 수 있습니다.
만약 화면에서 보시는 것처럼 9를 4로 읽는다든가 5나 8로 읽는, 즉 잘못 판단하는 경우가 많다면 논리모형의 정확도가 낮다고 볼 수 있겠고 그렇다면 모델의 정확도를 높이기 위해 노력을 해야 하겠지요.
즉 지속적으로 학습을 시켜서 평가에서 설정한 기준을 최적으로 만족하게 되면 이것이 바로 최적화가 되고 최적화 과정이 끝나면 학습 모델을 확정합니다.

이는 전문 용어로 가중치를 결정한다, 이런 의미인데요.
확정된 모델을 통해 새로운 데이터에 대해서 예측하는 것을 일반화라고 합니다.
이렇게 일반화가 끝나면 이 모델을 작업에 적용해야 하겠지요.
여러분이 관공서나 은행에 가서 전자패드로 여러분의 주민번호나 휴대폰번호를 입력한다고 할 때 이때 입력한 손 글씨를 컴퓨터가 인식할 수 있도록 해당 모델이 그 안에서 작동합니다.
사람이 필기한 문장은 비정형 데이터이기 때문에 이를 정형 데이터로 변환해야 컴퓨터가 처리를 할 수 있겠지요.

이러한 손 글씨 판독에는 MNIST를 사용합니다.
MNIST는 다음의 약자로 손으로 쓴 숫자들로 이루어진 대형 데이터베이스인데요.
숫자에 대한 머신러닝에 널리 이용이 되고 있습니다.
앞서 보여드린 사례는 머신러닝 알고리즘인 CNN을 이용해서 손 글씨를 판독한 예시로서 MNIST와 같은 이미지 분석에는 CNN, 즉 Convolutional Neural Network가 사용되는데 이런 것에 CNN이 이용되는구나, 그 정도만 여러분이 기억해주시면 되겠습니다.

교수님, 지금까지 강의에서 무수히 많은 알파고가 등장했는데 알파고 버전은 도대체 몇 개나 되나요?

지금 이 시간에도 새로운 버전의 알파고가 만들어지고 있을지는 모르지만 바둑과 관련해서 2017년도까지 총 4개의 알파고 버전이 개발된 것으로 알고 있습니다.

각 버전의 특징을 살펴보면 다음과 같은데요.
먼저 2015년 10월에는 알파고 Fan이 만들어졌고 2016년도 3월에는 알파고 Lee가 만들어졌습니다.
그리고 2017년도 5월에는 알파고 Master가 만들어졌고요.
2017년도 10월에는 알파고 Zero가 만들어졌습니다.
보시는 바와 같이 빠른 속도의 연산을 지원하기 위해서 하드웨어 스펙이 좋아지는 것이 확인이 됩니다.
가령 알파고 Fan의 경우에는 176GPU에 분산 컴퓨팅을 이용해서 정보를 처리했는데요.
알파고 Lee부터는 TPU를 이용해서 데이터를 처리합니다.
TPU는 Tensor Processing Units의 약자로서 이런 고속 연산 처리에 특화된 정보처리 프로세싱이라고 볼 수 있습니다.
그리고 알파고 Master와 Zero에 가서는 TPU 버전 2를 이용하고요.
분산 컴퓨팅 대신 단일 서버를 이용해서 고속 처리를 지원하게 됩니다.

이들 4개 버전의 경기 실적 한번 볼까요?
알파고 Fan의 경우에는 Fan Hui와의 대국에서 다섯 게임에서 다섯 번 다 이겼고요.
알파고 Lee는 이세돌 기사와의 대국에서 우리가 역시 잘 아는 바와 같이 다섯 번 경기에서 네 번 이기고 한 번 졌지요.
알파고 Master는 프로 기사들과의 대국에서 다 이겼어요. 60번 싸웠는데 60번 다 이겼습니다.
프로 기사들이 백전백패한 것이지요.

마지막 한 번 보시겠습니다.
알파고 Zero, 이것은 사람이랑 경기를 안 하고요.
알파고하고 경기를 했습니다.
즉 알파고 Lee, 알파고 Master, 약간 다른 버전의 알파고와 경기를 했는데 알파고 Lee와의 대국에서는 백전백승을 했습니다.
단 한 번도 안 졌어요.
그리고 알파고 Master와의 대국에서는 100전 89승 11패의 좋은 실적을 얻었습니다.
이처럼 2017년도에 만들어진 알파고 Zero는 인간을 상대로 승리한 알파고 Lee와 알파고 Master를 높은 승률로 승리했는데요.
이제 알파고의 적수는 사람이 아닌 또 다른 알파고가 되고 있습니다.

그러면 기존 프로그래밍과 머신러닝의 차이점은 무엇인가요?

질문한 내용 진짜 헷갈리지요.
이 부분에 대해서는 제가 반복적으로 설명을 드리고 있지만 여전히 혼동스러운 것 같습니다.
그림을 통해서 조금 더 쉽게 이해해보겠습니다.
기존 프로그래밍은 데이터가 규칙에 따라 결과물을 출력하는 형식으로 개발이 되는데 이 경우에 적용해야 하는 규칙을 파악해서 이 규칙을 일일이 하나하나 계속 입력해야 한다는 번거로움이 있습니다.
반면 머신러닝에서는 데이터와 출력 값을 같이 입력하면 스스로 규칙을 도출하기 때문에 사람이 일일이 규칙을 입력하지 않아도 된다는 장점이 있습니다.
다만 한 가지의 문제는 어떠한 이유로 그와 같은 규칙이 도출되었는지는 알 수 없다는 것입니다.
