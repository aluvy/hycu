
----------------------------------------------------------------------
10_03 지도학습
----------------------------------------------------------------------

[3 페이지]
머신러닝은 크게 지도 학습, 비지도 학습, 강화 학습으로 분류가 된다고 설명을 드렸는데요.
이것을 구분하는 기준은 학습 데이터 세트에 ‘레이블이 있느냐 없느냐’의 차이입니다.

레이블은 학습 데이터의 속성으로 개와 고양이 사진에 ‘얘는 개고, 얘는 고양이다.’
이걸 정의해주고 학습을 시키면 지도 학습이 되며 알아서 구분하도록 하면 비지도 학습이 되는 것입니다.
즉 지도 학습은 레이블이 있는 상태로 학습을 시키는 것이고 비지도 학습은 레이블이 없는 Raw 데이터를 학습시키는 것으로 그렇게 구분하면 될 텐데요.
그렇기 때문에 지도 학습에서는 개, 고양이로 분류가 가능하며 비지도 학습에서는 개인지 고양이인지는 모르지만 어쨌거나 생긴 것이 비슷한 종끼리 군집화하게 되는 것입니다.

강화 학습은 알고리즘이 수행한 결과에 따라서 수행 방식을 스스로 진화시켜나간다는 특징이 있습니다.
Demis Hassabis는 알파고의 업그레이드 버전을 소개하면서 인간의 기본은 입력하지 않았다고 했습니다.
즉 바둑 규칙만 입력하고 스스로 바둑을 두며 이기는 수를 배워나가게 했다는 것인데 이 알파고 Zero가 바로 강화 학습 기반의 알고리즘으로 탄생한 예가 됩니다.

강화 학습은 스스로 시행착오를 겪으며 학습하고 진화한다는 점이 기존 지도 학습이나 비지도 학습과의 가장 큰 차이점인데요.
이처럼 시행착오 과정을 거쳐서 학습하고 진화하기 때문에 사람의 학습 방식과 가장 유사하며 그러한 이유로 강화 학습을 인공지능의 핵심으로 보는 견해도 있습니다.

지도 학습에 대해서 살펴보도록 하겠습니다.
지도 학습의 개요입니다.
지도 학습이란 입력 데이터와 출력 데이터를 나타내는 하나의 데이터 세트를 가지고 새로운 입력 데이터를 받았을 때 출력 데이터를 예측하도록 하는 방식입니다.
지도 학습에서 사용하는 훈련 데이터는 문제와 답이 한 쌍으로 이루어져 있습니다.
지도 학습으로 개와 고양이를 구분하는 방법을 다시 한번 살펴보시겠습니다.
개발자는 학습 데이터 세트을 주고 새로운 이미지를 넣었을 때 개와 고양이를 구분하는 모델을 만들고자 합니다.
이를 위해 컴퓨터를 학습시켜야 되겠지요?
그래서 입력 데이터.
조금 더 구체적으로 말하면 사진의 픽셀 정보를 주고 이 이미지는 개다, 이 이미지는 고양이라고 이미지에 정보를 입력해 줍니다.
이러한 활동을 레이블링이라고 하는데요.
이때 컴퓨터는 픽셀의 수치 정보만 받을 뿐 그것이 무엇인지는 전혀 알지 못합니다.
이 상태에서 개나 고양이의 이미지를 보여주면 입력 데이터의 특징을 분석하고 레이블링의 정보와 비교해서 이것이 개인지 고양이인지를 판단해서 그 결과 값을 제시합니다.

스팸 필터링도 지도 학습의 결과물인데요.
스팸 필터는 어떻게 새 메일을 분류할지 학습함으로써 스팸 메일을 자동으로 걸러주는 역할을 합니다.
여러분이 이용하시는 이메일 보관함을 한번 확인해보시면 스팸 메일 보관함이 따로 있는 것을 알 수 있을 것입니다.
일단 스팸 메일이 들어오게 되면 스팸 메일은 스팸 메일 보관함에 자동으로 들어가게 되는데 그렇다면 이메일이 왔을 때 어떻게 이것이 스팸 메일인지 아닌지를 확인할 수 있을까요? 원리는 간단합니다.
수많은 스팸 메일을 머신러닝 알고리즘으로 학습시킨 후에 학습된 머신러닝 모델을 이용해서 스팸메일을 분류합니다.
이를 위해서는 많은 메일 샘플과 레이블, 즉 스팸 여부를 주고 훈련을 시켜야 하겠지요.
그러면 새로운 이메일이 왔을 때 그동안 학습한 스팸 메일과 비교해서 새로운 이메일이 스팸 메일인지 아닌지 컴퓨터, 즉 기계가 스스로 판단한 후에 스팸 메일을 스팸 메일함으로 옮겨주는 것입니다.
우리가 종종 받는 스팸 메일 중에 ‘Re : 문의에 대한 답변입니다.’ 이러한 메일이 있을 것입니다.
‘내가 문의한 게 있었나 보네?’ 이렇게 생각하면서 메일을 열어보게 되는데 이처럼 누구나 받아봄 직한 제목으로 클릭을 유도하는 것이지요.
이러한 스팸 메일조차도 인공지능이 잘 걸러주고 있습니다.
이처럼 스팸 메일에서 발견되는 공통적인 규칙을 컴퓨터가 스스로 찾아서 걸러주도록 하는 것이 바로 스팸 필터링의 작동 방식이 되겠습니다.
다만 아직까지는 스팸 필터링 기술이 완벽하지 않고 대략 5% 내외로 에러율이 있기 때문에 멀쩡한 메일이 스팸 메일함으로 가지는 않았는지 중간 중간 확인할 필요는 있습니다.

SNS를 하는 분들의 경우도 친구 추천 서비스를 경험해 보셨을 텐데요.
추천된 친구들이 내가 하는 일이나 내 관심 분야와 상당히 비슷해서 깜짝 놀라는 경우가 상당히 많습니다.
여기에도 머신러닝 기술이 적용되는데요.
컴퓨터는 소셜 미디어에 내가 올린 사진이나 글을 분석해서 내 관심사를 찾아냅니다.
만약 제가 전국 산을 돌아다니면서 비박한 사진을 많이 올렸다면 내가 비박에 관심이 많다는 것을 알고 비박과 관련된 사진을 자주 올리는 사람들을 친구로 추천하게 되는데요.
이 경우에 추천의 정확도는 얼마나 많은 사진을 학습했느냐에 따라 달라질 것입니다.

지도 학습에서 주로 이용하는 방식은 그림과 같이 분류가 가능한데요.
첫 번째는 분류, 두 번째는 회귀입니다.

분류는 각 선택 및 분류에 영향을 미치고 회귀는 연관된 측정값을 통해서 미래를 예측하는데 이용하는 방식인데 이 내용도 역시 하나하나 다시 한번 살펴보겠습니다.

먼저 분류입니다.
분류는 비슷한 특성을 가진 데이터끼리 나누는 것으로 지도 학습의 대표적인 방법입니다.
앞서 스팸 메일을 분류하거나 사진을 보고 고양이인지 개인지 구분하는 것은 모두 분류를 통해 진행이 됩니다.
분류는 Yes or No와 같이 두 개의 클래스로 분류하는 이진 분류와 세 개 이상 클래스로 분류하는 다중 분류가 있습니다.
이러한 분류는 영화나 음악에 대한 개인별 선호도를 예측하여 추천하거나 글자, 얼굴 등 사물을 인식하고 또 개인의 신용 등급을 정해주고 개인 파산 등 위험 수준에 있는 고객을 파악하는데 이용되고 있습니다.

두 번째는 회귀 분석인데요.
회귀 분석이란 시간에 따라 변화하는 데이터나 어떤 영향, 인과 관계를 예측하는데 필요한 상당히 유용하게 이용되는 통계적 기법입니다.
화면에서 보시는 표는 학생들의 학습 시간과 시험 점수를 보여주고 있습니다.
학습 시간이 증가할수록 시험 점수도 증가하는 모습을 보여줍니다.
어찌 보면 당연한 것인데 과연 몇 시간을 공부하면 몇 점이 나올지는 정확히 알 수 없지요.
이 데이터를 가지고 학습을 시키면 이에 해당하는 회귀 모델이 만들어집니다.
모델이 완성되면 학습 시간을 입력했을 때 그에 따른 대략의 시험 점수를 예측할 수 있게 됩니다.
예를 들어 학생이 7시간을 공부했을 때 어떤 결과치를 받을 수 있을지 알아보기 위해서 7이라는 입력 값을 회귀 식에 넣어보겠습니다.
그러면 X=7 이렇게 입력했을 때 인공지능이 학습을 통해 생성된 회귀 모델을 기반으로 Y=65, 즉 시험 점수를 65점으로 예측해 줍니다.

분류와 회귀, 둘 다 선을 이용하고 비슷해 보이는데 가장 큰 차이점은 무엇인가요?

분류는 이 데이터가 어디에 속한다, 아니다를 명확하게 보여주는 목적으로 사용이 되고 있고요.
회귀 분석은 추세나 방향성을 보여주는 목적으로 사용이 됩니다.

그림을 한번 보실게요.
좌측에 있는 분류는 십자가 모양의 데이터와 동그란 모양의 데이터를 완벽하게 갈라주고 있습니다.
이 두 개를 얼마나 정확하게 갈라주느냐에 따라서 분류의 정확도가 달라지는 것이지요.

그런데 회귀는 어떻습니까?
여기저기 퍼져 있는 데이터에 어떤 경향 치를 통해서 X값이 증가함에 따라 Y값이 어떻게 변하는지 하나의 추세 선으로 보여주고 있어요.
하나의 경향을 보여주는 것입니다.
그런데 여기 올라와 있는 데이터들이 다 선에 올라와 있지는 않아요.
선을 중심으로 모여 있습니다.

이를 통해 볼 때 분류는 선이 대상을 구분하는 용도로 사용되며 정확해야 하며 회귀에서는 흐름을 보여주는 용도로 사용이 되기 때문에 이 두 개는 조금 사용 용도가 다르다고 보시면 될 것 같아요.

가령 고객 군이 있는데 이 고객들 중에 VIP 고객과 VIP가 아닌 고객을 분류하기 위해서는 좌측의 그래프를 이용해야 하지만 고객이 우리 카드를 사용하는 기간에 따라서 사용 금액이 어떻게 증가하는지 또는 어떻게 감소하는지 보고 싶다고 하면 회귀 식을 이용해서 이러한 가설을 검증해야 하겠지요.

우리가 회귀 식을 이용하면 가까운 미래를 예측할 수 있습니다.
가령 학생들의 성적과 중도 이탈률을 예측할 수 있으며 전염병의 전파 속도나 주가를 예측할 수 있습니다.
일례로 인공지능 스타트업인 블루닷은 머신러닝을 이용해서 전염병의 확산을 예측한 바 있습니다.

2020년 초 블루닷은 신종 코로나 19 바이러스의 집단 감염을 가장 먼저 예측했는데요.
블루닷은 미국질병통제센터와 WHO보다 앞서서 신종 코로나 19의 확산을 경고한 바 있습니다.
이 블루닷은 여러 곳으로부터 방대한 데이터를 받아서 자연어 처리 기술과 머신러닝 기술을 이용해서 분석을 했는데요.
코로나 19 바이러스가 확산되는 상황에서 여러 나라의 언론 자료와 항공 티켓 데이터 그리고 동식물 질병 데이터 이런 것들을 수집해서 감염병의 확산을 예측했습니다.
인공지능 기술을 활용해서 감염병을 예측하고 확산을 방지할 수 있다는 것을 보여주고 있는데 블루닷에 대해서 잠깐 자세하게 살펴보고 넘어가겠습니다.

블루닷의 창업자이자 의사인 캄란 칸 박사는 2003년 사스 창골 당시 토론토에서 전염병 전문가로 일했는데 당시의 경험으로 블루닷을 창업했다고 합니다.
캄란 칸은 2003년에 바이러스가 도시를 압도하고 병원을 무력화하는 것을 지켜봤으며 전염병 추적 및 대응을 위해 더 나은 방법이 필요하다고 느꼈다고 밝혔습니다.

캄란 칸은 이후 지속적으로 연구한 끝에 블루닷을 창업했고 여러 기관으로부터 투자금을 유치했습니다.
블루닷은 여러 곳으로부터 확고한 방대한 데이터를 자연어 처리 기술과 머신러닝 기술을 이용해 분석했습니다.
데이터는 60개 이상의 언어로 돼 있으며 항공사 데이터 및 동물 질병 정보도 분석합니다. 다만 SNS상의 데이터는 신뢰할 수 없기 때문에 사용하지 않는다고 밝혔습니다.
흥미로운 사실은 블루닷이 감염된 사람의 예상 이동 경로를 파악하기 위해 글로벌 항공사 발권 데이터를 분석했고 그 결과로 우한에서 방콕, 서울, 타이베이, 도쿄에서 신종 코로나바이러스 감염자가 나타날 것으로 정확히 예측했다는 점입니다.
블루닷은 크게 두 가지 서비스를 제공하는데 블루닷 인사이트는 거의 실시간으로 전 세계 전염병을 추적하고 경고하는 서비스입니다. 블루닷 익스플로러 서비스는 전염병 분석을 위해 필요한 국가별 인구 밀도, 실시간 기후 정보, 곤충 및 가축 정보 등 다양한 데이터와 이를 통합적으로 분석하기 위한 각종 도구를 제공합니다.
블루닷은 AI를 통한 자동화된 데이터 분석과 인간의 검토를 거쳐 과학적인 결론을 도출합니다.

다음은 데이터로 훈련을 시키고 검증하는 과정에 대해서 함께 학습을 하시겠습니다.
머신러닝의 모델의 정확도를 높이기 위해서는 예측의 정확도를 검증하는 과정을 반드시 거쳐야만 합니다.
그런데 훈련을 시켰을 때 사용했던 데이터를 그대로 사용한다면 예측률은 어떻게 나올까요? 당연히 100%가 나오겠지요.

이처럼 동일한 데이터로 성능을 검증하면 정확도가 거의 100%로 나올 것이며 우리는 이것을 가지고 ‘성능이 우수하니까 바로 투입해야겠다.’
이렇게 생각하고 제품 및 서비스에 이 모델을 적용했다가 일을 크게 그르치게 될 것입니다.

엑스레이 사진을 보고 인공지능이 오판해서 멀쩡한 사람을 암 환자로 분류하거나 반대로 암 환자를 정상인으로 분류했다고 생각해보면 이것은 정말로 심각한 문제가 아닐 수 없습니다.

그래서 머신러닝으로 학습을 할 때는 전체 데이터 중 한 70~80% 정도로 따로 떼어서 이것으로 학습시키고 나머지 20~30% 정도는 검증하는 데에만 사용합니다.
이때 학습에 사용하는 70~80% 정도의 데이터를 훈련 데이터 세트로 나머지는 데이터를 테스트하는 테스트 데이터 세트로 구분합니다.

이들 데이터를 어떤 비율로 나눠야 할까요?
혹자는 7:3을 혹자는 8:2를 황금비율이라고 말하는데 너무 적지 않은 테스트 데이터 세트를 가져갈 수 있다고 하면 저는 비율은 크게 문제가 되지 않다고 봅니다.
즉 7:3이든, 8:2든 다 좋다고 보고요.
다만 이것에 대해서 또 한 번 나누는 과정이 필요합니다.

한 70~80% 정도의 훈련 데이터 세트는요.
다시 훈련 데이터와 검증 데이터로 구분이 됩니다.
앞서 말씀드리는 훈련 데이터, 검증 데이터, 테스트 데이터는 다음과 같이 활용이 됩니다.
먼저 훈련 데이터를 가지고 모델을 훈련시키고 검증 데이터를 가지고 현재 훈련 데이터로 훈련 중인 모델이 과적합 되고 있는 건 아닌지 이런 것들을 검증하면서 최적의 적합 구간을 찾아서 최종 모델로 결정을 합니다.

우리는 이것을 가중치 결정이라고 하는데요.
이후 테스트 데이터를 사용해서 최종 모델이 얼마나 잘 예측하고 분류하는지 평가를 해야 합니다.
여기서부터는 조금 어려운 개념을 설명을 드릴 것인데요.

바로 가중치와 과적합에 관한 설명입니다.
이 부분이 기술적인 부분이기 때문에 조금 어렵지만 앞으로 인공지능을 전문적으로 공부할 분들을 위해서 간단하게 설명을 드리겠습니다.

첫 번째는 가중치.
가중치란 영어로 weight라고 하는데요.
평균치를 산출할 때 각각 부여되는 중요도를 가중치라고 합니다.
가령 결혼을 앞둔 커플이 결혼식장을 구할 때 나는 신축건물에 비용이 저렴하고 지하철역에서 가까웠으면 좋겠다는 세 가지 조건을 가장 중요하게 여긴다면 다음과 같은 수식이 나오겠지요.
y, 즉 예식장 선택은 신축 여부+대관료+대중교통의 접근성 이런 식이 나올 것입니다.

하지만 이 세 가지 요소 중 더 중요하게 여기는 것이 있을 것입니다.
이렇게 공식을 바꿔야 하겠지요? y, 예식장 선택은 (신축 여부*1)+(대관료*2)+(대중교통 접근성*3) 이것이 바로 가중치의 개념입니다.

예비 신혼부부가 여러 개의 예식장을 물색을 해서 A, B라는 두 개의 예식장을 일단 선정을 했는데 A는 신축에서 5점, 대관료에서 3점, 대중교통 접근성에서 4점을, B는 신축에서 2점, 대관료에서 4점, 대중교통 접근성에서 5점을 받았다면 A는 최종적으로 23점을 받게 되고 B는 최종적으로 25점을 받게 되기 때문에 이 경우에는 무엇을? B를 선택해야 할 것입니다.

제가 가중치에 대한 이해를 돕기 위해서 매우 심플하게 설명을 드렸는데요.
머신러닝에서의 가중치란 입력 데이터를 변환해서 출력 데이터를 만들기 위한 변환 도구에 해당하는 점을 기억하시기 바랍니다.

인공 신경망, 즉 ANN에서는 가중치가 매우 중요한데요.

그림에서 보는 바와 같이 인공 신경망으로 데이터가 각각 입력되면 다음 뉴런으로 전달되는데 이때 입력 데이터는 가중치가 각각 달라서 각각 다른 값으로 전달이 됩니다.
데이터 1의 경우에는 h1에서는 0.5로 처리되지만 h2에서는 1로 처리가 되는 등 두 개의 데이터를 받아서 처리한 값이 각각 달라지게 되는데요.
이러한 과정을 계속 거친 후 출력 층에서 최종 값을 출력하게 되는 것입니다.
이처럼 가중치에 따라서 처음 입력된 데이터들이 계속 다른 값으로 변하면서 뉴런과 뉴런을 거쳐서 출력 층으로 나오기 때문에 모델의 정확도를 높이기 위해서는 가중치를 정확하게 결정하는 것이 매우 중요합니다.
그리고 이러한 가중치가 결정되었을 때 비로소 학습이 완료되었다고 봅니다.

앞서 우리가 학습했던 퍼셉트론에서는 데이터를 두 개의 분류로 이렇게 나누기 위해서 선형 경계를 찾았습니다.
이때 가중치는 선형 경계를 찾아주는데 매우 중요한 역할을 하는데요.
그림에서 보는 바와 같이 객체가 추가됨에 따라 경계선이 조금씩 달라지는데 어떠한 객체를 넣더라도 완벽하게 구분하는 그런 시점이 오면 비로소 학습이 완료되었다고 보는 것이지요.
이처럼 많은 훈련 데이터가 추가됨에 따라서 선형경계를 계속 조정해 가면서 분류의 정확도는 높아집니다.
여기서 가중치를 어떻게 주느냐는 모델의 정확도를 높이는데 가장 크게 영향을 준다는 점을 기억하시기 바랍니다.

두 번째는 과적합에 관한 개념을 설명 드릴게요.
일반적으로 모델의 적합도는 다음과 같은 세 가지로 나뉩니다.
화면에서는 세 가지 상황을 보여주고 있는데 가장 왼쪽에 있는 것은 부적합 상황으로 전혀 학습이 안 된 상태를 말하고요.
정 가운데에 있는 이 그림은 정적합으로 적절하게 학습이 이루어져서 대상을 잘 구분하는 상황입니다.
그러면 가장 오른쪽에 보이는 이 이상한 과적합의 상황은 무엇일까요? 과적합이란 모델이 훈련 데이터에는 너무 잘 맞지만 다른 데이터를 넣었을 때는 잘 안 맞아서 일반성이 떨어지는 현상을 말합니다.
적합하기는 적합한데 너무 과하게 적합해서 다른 쪽에는 응용이 안 되는 상황을 말하는 것이지요.
이는 학교에서 기출 문제 풀이를 엄청나게 시켜서 교내 시험은 잘 보는데 외부에서 치르는 실전형 시험에서는 낙방하는 상황과 같습니다.
그림을 보시면 파란색 선이 모든 데이터를 완벽하게 관통하는 모습을 보이고 있습니다.
그런데 선이 너무 복잡해서 오히려 어떤 대상을 구분하거나 미래를 예측하기는 어려운 상황입니다.
일종의 추세가 보여야 하는데 해당 선은 그렇지 못하지요.
이 경우 테스트 데이터를 넣었을 때는 성능이 매우 낮게 나올 가능성이 높습니다.

이러한 문제를 해결하기 위해서 우리는 세 가지의 방법을 이용하게 되는데 첫 번째는 충분한 양의 훈련데이터를 모으거나 두 번째는 정규화를 통해서 모델을 덜 복잡하게 만들거나 세 번째는 이상치를 제거하는 방법을 사용하게 됩니다.

이중 이상치는 영어로 outlier라고 하는데요.
이것은 잘못 입력되거나 아주 특이한 데이터를 말합니다.
예를 들어볼게요.
어느 중학교에서는 아이들 키를 측정해서 엑셀로 관리를 하고 있는데 중2 학생의 키를 입력한 표에 210이 있다고 가정해 보겠습니다.
이 경우는 둘 중 하나겠지요.
실수로 입력을 잘못했거나 아니면 서장훈과 같은 장신 학생이 있었거나 둘 중 하나일 것입니다.

그런데 이 이상치가 들어오면 해석에 중대한 왜곡이 발생하게 됩니다.
만약 한양중학교 2학년 학생들의 평균 키를 계산하기 위해서 표본을 딱 10개를 뽑았는데 210 데이터를 빼고 계산할 때는 164.5였던 평균 키가 210 데이터를 딱 포함하니까 170이 되었다면 210이라는 데이터 하나로 심각한 왜곡이 발생하게 되는 것입니다.

이 경우에는 당연히 이상치를 제거하는 조치가 필요하겠지요.
머신러닝도 마찬가지입니다.
화면에서 보시면 이러한 이상한 선이 나오게 된 가장 큰 원인을 제공하는 것, 즉 이상치는 바로 붉은색 데이터로 누가 보더라도 이상치에 해당하는 데이터라면 이상치를 과감하게 삭제해야 합니다.
이상치를 삭제한 상태에서 선을 그려보니까 어느 정도 상관관계를 그리면서 선이 예쁘게 나오지요.
이 선은 대상을 분류하거나 추세를 보여주는데 유용하게 사용이 될 수 있습니다.

실제로 모델을 개발할 때 훈련이 부족하면 부적합이 나타나고 필요 이상으로 많이 훈련시키면 과적합이 나오기 때문에 훈련을 중단하는 그 타이밍을 딱 잘 잡아야 되는데요.
이 타이밍을 잡는데 검증 데이터를 이용할 수 있습니다.

방법은 다음과 같습니다.
그림에서 보는 바와 같이 검증 데이터로 성능을 평가할 때 오류가 감소하다가 갑자기 증가하는 시점이 나타납니다.
이것이 바로 과적합이 나타나는 시점으로 이 시점에서 학습을 멈추면 과적합 문제를 해결할 수 있습니다.

교수님, 검증 데이터, 테스트 데이터 모두 모델의 적합도를 검증하기 위한 데이터로 보이는데 둘이 너무 비슷해 보입니다.

이런 질문들을 많이 하시지요.
답을 드리자면 검증 데이터와 테스트 데이터는 용도가 다르다는 것입니다.
검증 데이터는 과적합을 막기 위한 목적의 데이터이며 테스트 데이터는 모델의 적합도를 최종적으로 평가하기 위한 목적이기 때문에 이들의 용도는 전혀 다릅니다.

그러면 훈련 데이터와 테스트 데이터를 구분하지 않을 경우 어떤 문제가 있을까요?

앞서 이와 유사한 설명을 드렸는데 다시 한번 설명을 드려볼게요.
제가 학교에서 자격증 과목을 강의하는데 중간고사 전에 중간고사 맛보기 문제로 10문제를 냈습니다.
그런데 그 문제를 똑같이 중간고사에 냈다면 어떤 문제가 발생할까요? 맛보기 문제를 풀어봤다면 모든 학생들은 중간고사에서 높은 점수를 받겠지요.
이 경우에 어떤 학생이 정말로 열심히 공부했는지 변별할 수 없을 것입니다.
게다가 중간고사를 만점 받고 이대로 자격증 시험을 보면 붙을 거라 생각하고 자격증 시험에 응시했다면 이 경우 대다수가 시험에서 탈락할 것입니다.

즉 훈련 데이터로 검증할 경우에 새롭게 입력된 신규 데이터에 대해서는 모델이 작동하지 않거나 잘못된 출력을 나타낼 것이므로 처음부터 훈련 데이터, 검증 데이터, 테스트 데이터는 완벽하게 구분해야 합니다.
다만 한 가지 유의할 점은요. 이 세 개의 데이터가 모두 한 개의 소스에서 가져와야 한다는 것입니다.
가령 훈련 데이터는 A 백화점은 가져오고 테스트 데이터는 B 마트에서 가져온다면 모델의 적합도가 낮게 나타날 것이기 때문에 처음에는 세 종류의 데이터를 동일한 소스에서 가져와야 한다는 것을 기억하기 바랍니다.

머신러닝 모델은 복잡할수록 예측력이 좋은가요?
최대한 복잡하게 만들어야 할까요?

이것도 꼭 그렇지만은 않습니다.
왜냐하면 복잡한 모델, 즉 복잡한 곡선은 과적합을 유발할 수 있기 때문입니다.

이와 관련해서 오컴의 면도날이라는 개념이 있는데요.
오컴의 면도날은 어떤 현상을 설명할 때 불필요한 과정을 잘라내라는 의미로 경제 분야에서 많이 사용이 됩니다.

가령 택배 상자가 분실이 되었다는 접수가 들어왔습니다.
이 경우에 배달원이 실수로 다른 집에 가져다줬거나 고객이 물건을 받고 안 받았다고 떼를 뜰 수 있고요.
택배 배달원이 물건을 꿀꺽했을 수도 있고 더 최악의 경우는 택배 기사가 물건을 올리러 간 사이에 지나가는 행인이 물건을 슬쩍 했을 수도 있습니다.

이러한 네 가지 가정 중 가장 개연성이 높은 것은 바로 첫 번째지요.
즉 배달원이 실수로 다른 집에 가져다줬을 가능성이 높기 때문에 이렇게 타당도가 높은 첫 번째 가정에 집중해서 문제 해결 방안을 찾아야 되고 이것이 바로 오컴의 면도날에서 주장하는 경제성의 원리가 되겠습니다.

즉 오컴의 면도날 원리는 쓸데없이 복잡하게 만지지 말라는 뜻으로 이상치는 최대한 제거하라, 단순한 것이 최고라는 의미를 담고 있습니다.
머신러닝 역시 모델이 복잡하다고 성능이 좋은 것은 아니지요. 인공지능 전문가는 단순한 모델로도 최적의 결과를 내는 사람이라는 점을 기억하시기 바랍니다.





----------------------------------------------------------------------
10_04 비지도 학습과 강화학습
----------------------------------------------------------------------

[4 페이지]
다음은 비지도 학습에 대해서 함께 배워보겠습니다.
비지도 학습은 데이터 안에 스스로 특징과 구조를 발견해내도록 하는 방식인데요.
이러한 비지도 학습에는 훈련 데이터에 레이블이 없습니다.
즉 시스템이 인간의 지도 없이 학습을 하는 것이지요.

가령 개와 고양이의 이미지만 보여주고 개와 고양이의 이미지를 스스로 알아서 분류하도록 했다면 이것은 바로 비지도 학습에 해당합니다.

지난 시간에는 비지도 학습의 대표적인 알고리즘으로 군집에 대해서 설명을 드린 바 있습니다.
군집에는 k-평균, 즉 K-means 알고리즘이 많이 사용이 되는데 이것은 주어진 데이터를 지정한 클러스터 개수, 즉 k로 그룹핑을 하는 방식입니다.

만약 클러스터 개수를 4개로 지정한다면 컴퓨터가 알아서 비슷한 유형끼리 4개의 그룹으로 묶어주겠지요.
이러한 알고리즘의 결과는 센트로이드라고 불리는 k개의 포인트입니다.

이는 서로 다른 그룹의 중심을 나타내는데요.
모든 데이터는 k 클러스터 중 딱 하나에만 속할 수 있습니다.
한 클러스터 내의 데이터들은 다른 센트로이드보다 자신의 센트로이드와 거리가 가깝겠지요.

이러한 기저로 한 클러스터 내의 데이터들은 동일한 성질을 가지며 다른 그룹과 구별되게 됩니다.
군집 분석 일종인 계층 군집 분석은 비슷한 군집끼리 묶어가면서 최종적으로는 하나의 케이스가 될 때까지 군집을 묶는 방식인데요.
앞서 k-평균 알고리즘과는 다르게 군집의 수를 미리 정해주지 않아도 된다는 특징이 있습니다.

가령 편의점에서 판매하는 모든 음료를 계층 군집 분석으로 나누면 수십 개에 달하는 몇 가지의 음료수들이 한 일곱 개의 유사 제품군으로 이렇게 분류되는 모습을 보게 되는데 이것이 바로 계층 군집 분석 방법입니다.

즉 인공지능이 데이터의 유사성을 분석해서 알아서 그룹을 묶어주는 방식인데요.
예를 들어서 설명해 보겠습니다.
한양마트는 우수 고객에 대한 충분한 데이터를 확보하고 있습니다.
우수 고객을 구매 유형에 따라서 비슷한 유형끼리 묶어서 유형별 마케팅을 전개하고 싶습니다.
하지만 우수 고객들이 어떤 그룹에 속하는지 알려줄 수 있는 데이터 포인트를 맞지 못하는 상황인데요.
이에 알고리즘이 스스로 고객 사이의 연결고리를 찾고자 하며 이때 비지도 학습을 사용했습니다.
인공지능이 알아서 다섯 개의 그룹으로 나눠줬는데 각 그룹별의 특징을 분석한 결과 A 그룹은 식품을 주로 구매하고 한 번 구매 시 15만 원 이상 구매하는 특징이 있었으며 B 그룹은 생활용품을 주로 구매하고 한 번 구매할 때 평균적으로 10만 원 이상 구매한다는 특징이 있다는 것을 알게 되었습니다.

이처럼 군집 방식을 이용하면 대상을 비슷한 유형끼리 묶는데 도움을 줍니다.
기업에서 처리하는 데이터의 양은 엄청나지요.
이것을 사람이 수작업으로 나누거나 엑셀로 분류하는 것은 거의 불가능하며 이런 데이터를 어떠한 특징으로 구분할지 정하는 것도 역시 쉽지 않습니다.
이 경우에 인공지능을 이용해 각 데이터의 속성상 어떻게 묶이는지 어떤 데이터끼리 묶이는지 인공지능이 알려만 줘도 아마 큰 도움이 되겠지요.
다만 묶이는 그룹이 공통적으로 어떤 특징이 있으며 어떤 기준으로 묶이는지, 분류된 것인지는 분석 전문가가 해결해야 될 부분입니다.

군집 분석을 이용해서 기업들은 고객을 유사한 성향끼리 묶어서 고객들의 성향에 맞는 서비스를 개발할 수 있고요.
가령 물류센터, 홈쇼핑의 물류센터를 결정할 때도 군집을 이용할 수 있는데 특정 아이템에 대한 주문이 잦은 지역을 분석해서 그 지역과 가장 가까운 위치에 특정 아이템을 적재해 놓는 물류센터를 세우는 것에도 이 방법을 적용할 수 있습니다.

그 외에도 야간 약국의 위치를 선정할 때도 이 방법을 이용할 수 있습니다.
그리고 이상한 거래에 대한 승인을 요청할 때 카드 소유자에게 자동으로 경고 메시지를 전송해주는 부정사용 감지 시스템에도 이러한 군집 분석을 이용할 수 있습니다.

가령 A라는 사람은 보통 서울 지역에서 소액 중심으로 카드를 사용해요.
김밥 먹고 커피 마시고 버스 타고 꽃 사고 이런 소소한 것들을 사는데 주로 카드를 이용하는데 어느 날 이 A라는 사람이 부산 지역에서 신용카드로 500, 300만 원씩 딱딱 끊었다면 해당 소비 데이터는 아마 이상 거래로 분류가 되어야 하겠지요.
이것을 인공지능이 직접 분석을 해서 부정사용 여부를 이용자에게 자동으로 통제해 주는 그런 방식입니다.
이것은 항상 1등만 하던 반장이 50명 중 25등을 하면 반장한테 뭐가 문제가 있다고 생각하고 담임이 반장 엄마한테 전화를 해서 학교로 면담오라고 연락하는 것과 같은 이치일 것입니다.

이런 군집 외에도 차원 축소 등이 비지도 학습에 사용이 됩니다.

다음은 강화 학습입니다.
강화 학습이란 컴퓨터가 시도와 실패를 통해서 반복적으로 역동적인 환경과 상호작용함으로써 특정 과업을 수행하는 방법을 배우는 방식입니다.
강화 학습은 문제와 답을 주지 않고 특정 행동에 대해서 보상을 해서 컴퓨터를 학습시키는데요.
가령 이미지를 맞히면 10점, 틀리면 0점을 부여해서 컴퓨터 스스로가 개와 고양이를 구분하도록 지원하는 방식입니다.

예를 한번 들어 설명하겠습니다.
나애리는 자신이 키우는 강아지인 댕댕이를 훈련시키기 원합니다.
이를 위해서 막대기를 던져서 물어오면 간식을 주고 그렇지 않으면 간식을 주지 않으려 합니다.
댕댕이는 간식을 먹고 싶어서 짖어도 보고 주인에게 애교도 부려보지만 주인이 간식을 주지 않습니다.
주인의 행동을 곰곰이 관찰하면서 댕댕이는 막대기를 던졌을 때 이를 물어오면 간식을 준다는 것을 알게 되었고 이후부터는 간식을 먹기 위해 던져진 막대기를 물어옵니다.

이처럼 강화 학습의 목표가 되는 개를 Agent라고 말하지요.
Agent는 훈련의 대상이 됩니다.
이러한 Agent를 훈련시켜서 어떤 환경 속에서 과제를 완성하도록 하는 것이고 개 주인은 개와 상호작용하는 환경에 해당합니다.
개 주인이 어떠한 명령이나 단서를 제공하면 개는 그것을 관찰하고 이어서 개가 반응을 할 때 그 반응이 원하는 접근에 어떤 행동에 근접했다고 하면, 즉 정답이라고 하면 개 주인은 간식으로 보상을 하고 아니라고 하면 보상하지 않거나 벌을 줄 수 있지요.

이러한 알고리즘을 화면에서 보시는 다이어그램으로 표현을 해봤습니다.
컴퓨터도 인간의 개입 없이, 즉 어떤 과제를 달성하기 위해 프로그래밍이 되지 않고도 보상을 극대화함으로써 정확한 결정을 이끌어낼 수 있습니다.

이것이 바로 강화 학습의 원리입니다.
강화 학습은 딥마인드가 게임을 가르칠 때 사용한 방식인데요.

다음 게임 방식을 함께 보도록 하겠습니다.
여러분, 보시는 것이 약간 스도쿠하고 비슷한데 게임 방식이 조금 다릅니다.
빙고에 가깝다고 해야 하나? 9개 칸에서는 나란히 3개 칸을 점령하면 이기는 게임인데요.
이 화면에서는 컴퓨터가 X고 사람이 O입니다.

하나하나 볼게요.
첫 번째 주어진 판은 9개의 매트릭스에 O, 빈 공간, X, X, 빈 공간, 빈 공간, X, O, O라는 것이 주어졌습니다.
즉 이미 컴퓨터가 세 개의 말을 놓고 사람이 세 개 말을 놓은 상태에서 이 세 개의 빈 공간에 말을 어떻게 놓느냐에 따라서 컴퓨터가 이길 수도 있고 사람도 이길 수 있는 게임이지요.

2번 시나리오로 가겠습니다.
만약 컴퓨터가 가운데에 X를 놓으면 어떻게 될까요? 세 개가 크로스로 연결이 되기 때문에 이 경우에는 컴퓨터한테 너 잘했어, 그러면서 10점을 주는 것입니다.
컴퓨터의 선택에 의해서 충분한 보상이 이루어진 것이지요.

3번 시나리오 가 보겠습니다.
이 컴퓨터가 X를 조금 이상한 데 놨어요.
그래서 맨 위 칸 빈 공간에 놨습니다.
그러면 사람이 패를 쥐게 됩니다.
그랬을 때 5번 시나리오에서 보는 것처럼 사람이 가운데에 동그라미 말을 놨다면 이 경우에는 반대 케이스로 크로스가 되기 때문에 이 경우에는 사람이 이기는 것이지요?
‘야, 너 왜 이렇게 말을 놨니?’ 이러면서 이 컴퓨터에 페널티를 줍니다.
즉 -10점을 주는 것이지요.

여섯 번째 시나리오 가보겠습니다.
사람도 조금 멍청한 판단을 했네요.
가운데에 안 놓고 맨 우측 가운데 동그란 말을 놨습니다.
그러면 9번 시나리오로 가서 컴퓨터는 남아 있는 공간에 본인의 말을 놓으면 왼쪽으로부터 오른쪽까지 이렇게 사선으로 연결이 되기 때문에 이 경우에는 10점을 받게 되는 것이지요.

4번 시나리오로 가볼까요?
4번에서는 컴퓨터가 중간에 말을 놓습니다.
그런다고 하면 사람이 가운데를 점령하면 사람이 이기는 게임, 역시 7번 시나리오에서는 컴퓨터가 페널티를 먹게 됩니다.
-10점이 부여되고 8번에 갔더니 사람이 또 실수를 했어요.
가운데에 놓으면 이기는 게임인데 맨 상단 가운데에 말을 놨습니다.
이 경우에 역시 컴퓨터는 남아 있는 가운데에 자신의 말을 놓음으로써 게임에서 이기고 이러한 결과로 10점을 받게 되는 것입니다.

이런 식으로 컴퓨터는 게임에서 이기는 방법을 스스로 체득하게 되는데요.
앞서 딥마인드가 아타리 게임을 배우면서 인간을 초월하는 놀라운 실력을 가지게 된 것은 바로 이러한 강화 학습 덕분입니다.

지금까지 여러분은 지도 학습, 비지도 학습, 강화 학습에 대해서 학습하셨는데요.

중요한 내용을 다시 하나하나 정리해보면 다음과 같습니다.

첫 번째, 기계 학습은 무엇으로 구성이 된다? 지금 화면에 블랭크로 돼 있지요.
왼쪽 블랭크에 들어갈 것은 지도 학습, 가운데 블랭크에 들어갈 것은 비지도 학습, 나머지 블랭크에 들어갈 것은 강화 학습입니다.
지도 학습, 비지도 학습, 강화 학습 잘 넣으셨고요.
지도 학습의 특징은 레이블 된 데이터로 학습을 한다는 것입니다.
즉 고양이의 사진에 고양이라는 데이터, 메타태그를 같이 넣어서 제공했다면 이 경우에는 지도 학습에 해당하며 이것은 미래의 데이터를 예측하는데 많이 이용이 되며 지도 학습의 대표적인 방법은 분류와 회귀가 있다고 말씀을 드렸습니다.

분류 같은 경우에는 MNIST에서 필기체를 인식하는 방법에 많이 이용이 되고요.
또 스팸 메일을 자동으로 분류해주는 알고리즘에도 분류 방식이 이용이 됩니다.
반면 회귀는 주가를 예측하는 것처럼 미래 추세를 파악하는데 이용이 되며 이 역시 지도 학습을 통해서 만들어질 수 있는 알고리즘의 하나입니다.

비지도 학습은 레이블 없이 학습합니다.
이것이 개인지 고양이인지 알 수 없지만 비슷한 아이들끼리 이렇게 두 개로 구분했다고 하면 이것이 바로 비지도 학습이 되는 것이지요.
분류와 군집은 여기서 다릅니다.
분류는 이것이 개인지 이것은 고양이인지는 구분해서 알려주는 거라고 하면 군집은 이 두 개가 다른 집단인데 이것이 개인지 이것이 고양이인지 모른 상태에서 그냥 외형만 가지고 구분했다고 하면 이것이 바로 군집에 해당하는 것이지요.

이러한 군집은 데이터의 숨겨진 구조나 특징을 발견할 때 매우 유용하며 마케팅 고객을 그룹화할 때 우리는 이 군집 방식을 이용할 수 있습니다.
마지막으로 강화 학습은 보상 시스템으로 학습을 하는 방식이라고 말씀을 드렸지요.
이러한 강화 학습은 기업에서 의사결정을 위한 최적의 액션을 선택할 때 이러한 강화 학습 방법을 사용할 수 있습니다.

이러한 지도 학습과 비지도 학습을 조금 구분해서 다시 한번 정리해보면 지도 학습은요.
예측 모델을 생성하기 위한 목적으로 사용하는 반면 비지도 학습은 데이터를 분류하기 위한 목적으로 사용이 됩니다.
이때 지도 학습에 입력되는 정보는 레이블이 된 데이터고 비지도 학습은 레이블이 없는 데이터가 들어가게 되는 것인데요.
이러한 지도 학습의 유형은 그룹별로 특징을 파악하는 분류나 상호 간의 상관관계를 나타내는 회귀로 유용화 되며 비지도 학습은 데이터끼리 묶어지는 군집이라고 제가 몇 번을 말씀을 드렸어요.

이것 시험 문제에 내면 꼭 여러분, 맞히셔야 합니다.
이러한 지도 학습의 장점은 사람의 목표 값에 개입해서 정확도가 높다는 점.
그다음에 교차 검증을 통해서 성능 평가가 가능하다는 점이 장점이고요.
비지도 학습은 목표 값을 정해두지 않아도 되기 때문에 학습 속도가 빠르다는 점이 장점인 반면 검증 방법이 없다는 것이 이 비지도 학습의 단점이 됩니다.
단점 볼까요?
지도 학습은 시간이 오래 걸리고 요구되는 학습 데이터가 많아요.
많은 데이터를 투입해야지 지도 학습이 이루어지는 반면 비지도 학습의 단점은 학습의 결과로 분류 기준과 군집 예측이 불가능하다는 것입니다.

이런 것들을 알아내기 위해서는 분석 전문가가 2차 분석을 해줘야 해요.
관련 사례 하나 보도록 하겠습니다.
소득 수준과 신용도를 기준으로 카드 발급 여부를 판단하는 데에도 머신러닝을 이용할 수 있다고 했는데 새롭게 투입된 데이터를 어떻게 판단할 수 있는지 그 과정을 보여드리도록 하겠습니다.
그림에서 보는 바와 같이 별표와 세모는 기존 관측 치로 별표는 신용카드 발급을 승인받은 사람이며 세모는 승인을 받지 못한 사람들입니다.
이때 네모라는 사람이 신용카드를 발급해달라고 요청했을 때 이 사람한테 발급을 해줘야 할까요, 말아야 할까요? 우리가 배운 바를 적용해본다면 기존 관측 치와 거리를 계산해서 가까운 관측치가 많은 쪽으로 이 사람을 분류해 넣어야 할 것입니다.
즉 신용카드 발급 승인을 받은 사람들의 소득과 신용 점수가 유사도가 높다면 승인을 해줘야 하겠지만 그렇지 않다면 승인을 해주지 말아야 하겠지요.

그림에서 보시는 바와 같이 가장 가까운 여섯 개의 데이터와 거리를 구해본 결과 여섯 개의 비교 대상 중 세 개와 거리가 가장 가까운데 이는 다 별표, 발급 대상이었습니다.
나머지 세 개 중 두 개도 별표, 발급 대상이었고요.
그중 단 하나만 발급 대상 안 됐던 세모였습니다.

즉 가장 가까운 여섯 개의 데이터 중 다섯 개가 신용카드 발급 대상에 해당했기 때문에 다수결에 따라 네모를 신용 카드 승인 그룹으로 분류할 수 있을 것입니다.

우리는 이러한 방법을 KNN이라고 하는데요.
KNN은 K-Nearest Neighborhood의 약자로서 이 또한 머신러닝에서 사용되는 모델입니다.

오늘은 머신러닝에 대해서 전체적인 내용을 학습하셨는데 여러분이 조금 오해하기 쉬운 내용을 중심으로 해서 간단하게 다섯 가지의 퀴즈를 준비해봤습니다.

한번 여러분, 스스로 풀어보시고 저와 정답 맞혀보도록 하겠습니다.
첫 번째 문제, 다음 중 실제 출력 값과 정확한 출력 값을 비교해서 즉 교차검증을 통해서 오류를 검출하면서 학습하는 방식은?
1번 지도 학습, 2번 비지도 학습, 3번 강화 학습.
이것 제가 바로 전전 프레임에서 설명을 드렸지요? 정답은 무엇이다?
정답은 지도 학습.
교차 검증을 통해서 오류를 검출할 수 있다는 것은 지도 학습의 가장 큰 장점입니다.

두 번째 문제, 머신러닝 알고리즘인 CNN을 이용해서 손 글씨를 판독할 때 어떤 방식이 이용되는가?
첫 번째 분류, 2번 회귀, 3번 군집이었지요.
이것은 정답이 무엇일까요?
정답이 2번 분류입니다.
사람이 손으로 막 쓴 필기체를 인식해서 이것을 1로 분류할 것인지 2로 분류할 것인지 9로 분류할 것인지를 판단했기 때문에 이 경우에는 분류라는 알고리즘을 이용하는 것이지요.

3번 문제, 신경망은 예측력은 좋으나 도출된 결과에 대한 해석과 근거를 찾아내기 어렵다.
O, X. 이거 두 개 중 정답은?
O입니다.
이것은요. 신경망의 단점을 잘 보여주고 있어요.
예측력은 기가 막힌데 이런 결과에 대한 해석 근거를 바로 확인하기 어렵고 어떻게 해야 한다?
2차 분석을 통해서 이런 것들을 뽑아내는 것이 인공지능 전문가가 해야 할 활동입니다.

4번 문제, 군집 분석은 유사한 속성을 가진 데이터를 분류하는 방식으로 주로 지도 학습에서 이용된다.
보기는 O, X인데요. 이중 정답은 무엇이다?
정답은 X입니다.

마지막 5번 문제, 가중치의 설정은 무엇에 의해 결정되며 머신러닝 모델의 정확도를 높이기 위해서는 충분한 무엇을 모아야 한다.
이 두 개는 답이 조금 다르지요.
첫 번째 가운데에 들어갈 정답은 무엇이다? 학습입니다.
가중치의 설정은 학습에 의해서 결정된다고 말씀을 드렸고요.
두 번째 괄호 안에 들어갈 정답은 학습 데이터, 머신러닝 모델의 정확도를 높이기 위해서 우리는 충분한 학습 데이터를 모아야 한다.
그렇게 설명을 드렸습니다.





----------------------------------------------------------------------
10_05 Outro
----------------------------------------------------------------------

[5 페이지]
머신러닝, 기계가 어떻게 학습을 하는 거지? 머신러닝에서 말하는 학습의 의미는 무엇인가요?

이런 질문에 대해서는 여러분 스스로가 다양한 의견을 제시할 수 있을 것이라고 생각을 하는데요.
저는 오늘 학습 내용에 충실하게 답변을 드리겠습니다.
머신러닝이 학습을 한다는 것은 충분한 데이터를 가지고 과적합이 발생하지 않을 만큼 적당하게 훈련을 해서 정확한 가중치를 찾아내는 것이다.

머신러닝을 통해서 정확하게 대상을 인식하고 분류하고 예측하기 위해서는 알고리즘을 잘 만드는 것이 중요합니다.
하지만 기계를 제대로 학습시키기 위해서는 좋은 데이터를 풍부하게 가지는 것이 무엇보다 중요합니다.

오늘의 강의를 관통하는 오늘의 한마디입니다.
‘We don’ have better algorithms, we just have more data.’ 우리는 더 나은 알고리즘을 가진 것이 아니라 더 많은 데이터를 갖고 있을 뿐이다.
