----------------------------------------------------------------------
11. 인공지능의 끝판왕! 딥러닝
----------------------------------------------------------------------

[1 페이지]
어떤 사진이 진짜 사람의 이미지일까요?
당연히 4개의 사진이 모두 실제 사람의 이미지 같지만 사실 세 번째 사진을 제외한 나머지 사진은 컴퓨터가 합성해서 만든 가상의 이미지입니다.

그래픽카드로 유명한 엔비디아가 인공지능 기술을 이용해 진짜 같은 가짜 얼굴 이미지를 만들어내는 사이트를 만들었습니다.
웹페이지에서 새로고침을 할 때마다 다른 인물사진이 뜨는데요.
이들은 모두 현실에는 없는 가짜인물들이지만 실존인물이 아니라는 것이 믿어지지 않을 정도로 자연스럽습니다.
'이 사람은 존재하지 않습니다.' 인공지능의 끝판왕 딥러닝을 학습하겠습니다.





----------------------------------------------------------------------
11_02 딥러닝 개요
----------------------------------------------------------------------

[2 페이지]
오늘 학습할 주제는 딥러닝인데요.
딥러닝이란 여러 층을 가진 인공신경망을 이용해서 학습을 수행하는 것으로써 우리말로는 심층학습이라고 합니다.

딥러닝은 머신러닝의 한 분야인데요.
인공신경망 중에서도 층이 깊은 모형을 사용하는 분야를 의미하며 그 외의 조건은 사실 머신러닝과 거의 유사합니다.
딥러닝의 대표적인 응용분야로 자율주행자동차를 들었는데요.
자율주행차의 핵심은 자동차의 능동적이고 정확한 의사결정에 있고 이것을 딥러닝이 지원합니다.

우리가 차를 몰다 보면 운전자가 직접 판단을 해야 되는 경우가 많은데요.
그 모든 상황에 대해 미리 학습시키는 것은 사실상 불가능합니다.
자율적으로 작동하는 기기의 발생가능한 모든 상황을 미리 프로그래밍한다 하더라도 대응이 불가능한 예외사항은 발생하기 마련인데요.

이러한 예외사항에 대해 프로그래밍이 되어 있지 않다면 문제상황에 대해 아무런 조치를 하지 못하기 때문에 대형사고가 발생할 것입니다.
그런데 문제상황에 따른 최적의 솔루션을 자동차 스스로 도출해낼 수 있도록 한다면 어떨까요?

이것을 가능하게 하는 기술이 바로 딥러닝 기술입니다.
딥러닝은 인공지능의 성능을 스스로 계산해서 안전한 주행을 보증해야 되는 자율주행차의 필수적인 기술로 자리 잡고 있습니다.

딥러닝도 역시 인공신경망을 이용하고 있습니다.
인공신경망은 인간의 신경망을 모방한 네트워크지요.
인간의 두뇌에서는 신경세포인 뉴런이 여러 개로 연결되면서 복잡한 망을 형성하고 있지요.
인간의 뇌에서 뉴런들이 어떤 신호, 즉 자극을 받고 그 자극이 어떠한 임계값을 넘어서면 신호를 전달하게 되는데 그 과정에서 착안한 것이 바로 인공신경망입니다.

그럼 자극이 어떠한 임계값을 넘어선다는 게 어떤 의미일까요?

우리가 누군가를 꼬집는다고 한번 가정해 보겠습니다.
우리가 살짝 잡으면 별 반응이 없지만 꽉 꼬집으면 '아야!' 이러면서 상대방이 화를 내겠지요.
이 자극이 어떠한 임계값을 넘어서면 통증신호로 이어지는 그것과 같은 이치일 겁니다.

즉, 정리하면 외부로부터 들어온 자극, 즉 신호는 인공신경망에서 입력데이터에 해당하며 임계값은 가중치, 자극에 의해 어떤 행동을 나타내는 것은 출력데이터와 하나하나 매칭된다.
이렇게 설명드릴 수 있겠습니다.

그런데 이때 입력층과 출력층 사이에 다중의 은닉층, 즉 히든 레이어를 포함할 때 우리는 이것을 심층신경망, 즉 deep neural network라고 부릅니다.
기존의 머신러닝 알고리즘은 하나의 입력과 하나의 출력층으로 이루어져 있으며 많아야 중간에 하나의 은닉층을 가지고 있었습니다.

이런 구조의 신경망을 우리가 얕다고 표현하는데 2개 이상의 은닉층을 갖는 경우에는 그 신경망을 깊다고 표현하고 그래서 deep, 딥러닝이라고 부르는 것입니다.

중간에 은닉층이 많아지면 그만큼 알고리즘이 고도화될 수 있는 것이지요.
이처럼 다수의 은닉층을 가진 심층신경망은 딥러닝의 핵심 알고리즘이며 심층신경망은 다양한 형태로 발전해나가고 있습니다.

그렇다면 딥러닝의 이 은닉층이 많으면 어떤 점이 좋을까요?
이 또한 사례를 통해 살펴보시겠습니다.

화면에서 보시는 것처럼 인공지능에게 어떤 인물을 보여줍니다.
그러면 인공지능은 이미지를 흰색과 검은색이라는 픽셀로 인지를 합니다.
아직까지는 이 사람이 누구인지 몰라요.
다만 흰색과 검정색을 통해서 그냥 윤곽 정도를 확인하는 거지요.
그다음에는 가장자리의 이미지를 식별하고요.
또 그다음 단계에서는 가장자리의 이미지를 퍼즐처럼 조합해서 이 사람의 겉모습, 외형, 아주 희뿌연 그런 모습을 인식하게 됩니다.

이 사람은 머리가 하얗고, 얼굴이 동그랗고 목까지 나와 있는 이미지구나.
그 정도로 인식하게 되는 거지요.

그런 후에는 중앙으로 갑니다.
인물의 눈, 코, 입을 각각 인식하고요.
그 이후에는 눈, 코, 입의 이미지를 조합해서 최종적으로는 그 인물을 인지하고는 이 사람을 미국의 초대대통령인 조지 워싱턴으로 판단하게 됩니다.

만약 은닉층이 여기에 더 추가된다면 대상 인물을 좀 더 정확하게 식별할 수 있겠지요.
실제로 구글과 같은 기업에서 개발한 딥러닝은 1만 개 정도의 은닉층을 가지고 있대요.
물론 이것은 일반적인 상황은 아니고요.
보통 많으면 1천 개 정도를 말합니다.

그러면 여기서 신경망, 즉 ANN과 심층신경망 DNN의 차이를 하나하나 비교해 볼까요?
먼저 신경망은 은닉층의 개수가 통상 1, 2개 정도인 반면 심층신경망은 1개 이상에서 1,000개까지 은닉층의 개수가 상당히 다양하고 많습니다.

신경망에서의 알고리즘은 역전파 알고리즘라는 건데요.
사실 이거 되게 중요한 개념인데 제가 이번 수업에서 안 가르쳐 주겠어요.
왜냐하면 이거 알려드리면 대부분 인공지능은 나와 인연이 없나 보다, 이렇게 포기할 만큼 복잡한 알고리즘이어서 제가 설명을 안 드렸는데 그냥 신경망에서는 역전파 알고리즘을 쓰는구나, 그 정도만 여러분들이 아시고 넘어가도 되겠습니다.

그리고 심층신경망에서는 딥러닝 알고리즘을 사용하지요.
이러한 신경망이 주요 알고리즘으로 이용되었던 시기는 1980년대 후반, 정확히 말하면 1986년 이후고요.
심층신경망이 주로 이용되던 시기는 2006년 이후입니다.

신경망에서는 학습용 데이터 정도로 이용하지만 심층신경망에서는 대규모의 데이터를 이용합니다.
즉, 학습용 데이터는 학습을 위해서 미리 만들어놓은 데이터라고 하면 심층신경망은 현장에서 리얼타임으로 발생하는 엄청나게 많은 그런 데이터를 가지고 분석을 하고 있어요.
이런 신경망은 이론상으로는 실행시간이 많이 걸리고요.
심층신경망은 은닉층 개수가 많기 때문에 실행시간이 신경망보다 훨씬 더 오래 걸린다는 특징이 있습니다.

마쓰오 유타카가 쓴 [인공지능과 딥러닝]이라는 책을 보면 인공지능을 그 수준에 따라 4개의 레벨로 구분하고 있는데요.
1 레벨에서는 단순 제어 프로그램 탑재 수준으로 인공지능 청소기, 인공지능 세탁기와 같이 제어공학의 범주 내에 들어가 있는 수준을 레벨 1로 정의하고 있습니다.
2 레벨에서는 장기 프로그램, 청소로봇, 질문에 대답하는 인공지능 등이 여기에 속하는데 지극히 많은 입력과 출력의 조합수를 판단하기 위해서 추론탐색, 판단하는 프로그램 수준을 우리는 레벨 2로 분류합니다.
3 레벨은 검색엔진이 내장되어 있거나 빅데이터를 바탕으로 자동적으로 판단하는 인공지능인데요. 추론의 구조나 지식베이스가 데이터를 바탕으로 학습하는 것으로 이것은 머신러닝의 알고리즘이 이용됩니다.
마지막 4 레벨은요.
기계학습, 즉 머신러닝을 할 때 데이터를 나타내기 위해서 사용되는 입력값, 즉 특징 자체를 학습하는 딥러닝으로써

이번 시간에 배우는 딥러닝은 어디에 해당한다? 그렇지요.
레벨 4에 해당한다고 이해할 수 있겠습니다.

이처럼 보면 기술성숙도가 매우 높은 기술이 바로 딥러닝이라는 사실을 알 수 있습니다.

앞서 우리가 10차시 수업에서는 훈련데이터에만 딱 들어맞고 현실세계의 데이터를 넣을 때 정확도가 낮아지는 그런 과적합 문제를 방지하는 것이 매우 중요하다고 설명드렸는데요.
딥러닝에서도 과적합을 막기 위한 정교화가 매우 중요합니다.

이런 DNN의 정교화 기법 중에 multi-task learning이라는 기법이 있는데요.
이것은 결과값을 예측하는 과업을 2개 주는 겁니다.

가령 프라이드치킨을 만들기 위해서 생닭을 소분하는 것을 가르친다고 할 때 우리 가게에서는 800g만 써요.
그래서 800g만 시켜야 될 텐데 800g만 주는 게 아니고요.
1.2kg짜리도 주고 소분을 시키는 겁니다.
그러면 연습생은 800은 800대로 소분해보고 1.2kg짜리는 1.2kg짜리대로 소분을 해야 될 텐데 이 중량감이 다른 2개를 각각 소분을 해야 되면 처음에는 조금 힘들어하겠지만 생닭의 크기에 따른 소분방법을 익힐 수 있을 거고요.
나중에는 닭 중량이 어떻든 신속정확하게 소분을 할 수 있게 됩니다.

이처럼 multi-task learning은 우리가 수행하고자 하는 과업과 유사한 과업을 하나 더 추가해서 학습을 시키는 방법으로 유사한 과업을 하게 학습시킴으로써 특정 과업에 과도하게 집중해서 발생하는 과적합을 막아주고요.
유사한 과업에 투입했을 때 고르게 좋은 성과를 낸다는 장점을 기대할 수 있습니다.

이런 딥러닝을 학습시키는 데는 Keras, Caffe, Theano, PyTorch, TensorFlow 등 정말로 다양한 도구를 사용할 수 있는데요.
2018년도의 랭킹을 보면 여러분이 보시는 바와 같이 TensorFlow, Keras, PyTorch 순서로 영향력이 큰 것을 알 수 있습니다.

Keras의 경우에는 간결하고 가독성이 높아서 입문자한테 적당하고요.
이후 단계로 TensorFlow와 PyTorch를 많이 사용하고 있는데 다음에서는 최근 가장 많이 사용하고 있는 TensorFlow, PyTorch, Keras에 대해서 아주 간단하게 살펴보도록 하겠습니다.

첫 번째는 TensorFlow입니다.
TensorFlow는 딥러닝을 쉽게 구현할 수 있도록 다양한 기능을 제공해주는 일종의 오픈소스 라이브러리로 이것은 구글에서 개발했고요.
현재 검색, 음성인식, 번역 등 구글 앱에서 많이 사용이 되고 있습니다.

TensorFlow를 이름 그대로 풀자면 텐서를 흐르게 한다쯤으로 해석이 가능할 텐데요.
텐서 간 다양한 연산을 논리적인 구조로 미리 정의해놓고 정의된 논리 데이터, 논리 구조에 데이터를 넣어서 데이터가 흐르도록 한다는 의미를 갖고 있습니다.

TensorFlow의 Tensor란 물리학에서 사용하는 개념인데요.
이것은 다차원의 성격을 가지는 대상을 말합니다.
일반적으로 벡터는 2차원이지만 텐서는 3차원 이상을 내포합니다.

우리가 배우는 딥러닝에서는 투입되는 다차원 정보를 바로 텐서라고 지칭하는데요.

다음에서는 TensorFlow의 개념을 2가지로 나눠서 살펴보도록 하겠습니다.
첫 번째는 TensorFlow의 의미입니다.
TensorFlow에서의 계산은 데이터 흐름그래프로 이루어지는데요.
데이터들이 연산그래프를 따라 흐르면서 연산이 자연스럽게 일어나고 그 과정을 통해서 결과값이 도출됩니다.
즉, 딥러닝에서 데이터를 의미하는 Tensor와 데이터 플로우 그래프를 따라 연산이 수행된다는 Flow를 합쳐서 TensorFlow라는 이름이 붙여진 것입니다.

두 번째는 오픈소스 라이브러리인데요.
TensorFlow는 오픈소스 라이브러리라고 설명을 드렸습니다.
그러면 오픈소스 라이브러리는 어떤 의미를 갖고 있을까요?
먼저 라이브러리란 컴퓨터 프로그램에서 자주 사용되는 프로그램들을 모아 놓은 것으로써 목수들이 사용하는 연장을 모아놓은 일종의 연장통을 말합니다.
그리고 오픈소스란 소스 프로그램이 공개되어 누구나 자유롭게 수정하고 재배포할 수 있는 프로그램을 말합니다.
즉, 오픈소스 라이브러리는 알고리즘을 구현하는 데 필요한 각종 소스코드를 무료로 배포한 것을 모아놓은 것으로 개발자들의 쉬운 접근과 활용을 지원합니다.

이를 종합하면 TensorFlow는 딥러닝 알고리즘을 구현하는 데 필요한 다양한 프로그램을 무료로 제공하는 개발지원 도구다.
이렇게 설명할 수 있겠습니다.

TensorFlow는 데이터 플로우 그래프를 통해서 결과값을 직관적으로 보여주고 또 아이디어 테스트에서 서비스 단계까지 폭넓게 이용될 수 있으며, 계산구조와 목표함수만 우리가 정의하면 자동으로 미분을 계산해준다는 장점이 있어요.

화면에서 보시는 바와 같이 분석결과를 이해하기 쉽게 그래프로 보여주고 있지요.
그런데 이렇게 좋은 TensorFlow가 페이스북이 선도하는 PyTorch에 비해서 생산성이 부족하다는 지적을 받고 있습니다.
PyTorch도 딥러닝 알고리즘 개발을 한때 도와주는 지원용 오픈소스 라이브러리로 TensorFlow보다 조금 늦게 개발되어 이용자는 다소 적지만 모델에 대한 수정 보완이 용이해서 하이 레벨 개발자, 즉 개발자들 중에 좀 고수에 해당하는 사람들한테는 좀 더 매력적인 개발도구라고 볼 수 있겠습니다.

TensorFlow와 PyTorch의 가장 큰 차이점은 알고리즘에 대한 수정 가능성인데 TensorFlow는 논리적인 구조를 미리 정의해놓고 거기에 데이터를 넣어서 결과값을 보는 데 최적화되어 있지만 내 마음대로 알고리즘을 수정하기 사실 쉽지 않습니다.

반면 PyTorch는 알고리즘을 로우 레벨부터 짜거나 신경망의 구조를 프로젝트에 딱 맞는 구조로 학습시켜서 최적의 결과물을 내도록 지원하는 거지요.
이미 많은 사람들이 TensorFlow에 익숙해져서 고착효과가 나타나고 있습니다.
영어로는 lock-in 효과라고 하는데요.

고착효과는 누군가를 lock시키는 거예요.
잠가버리는 거예요.
특정 제품을 사용해본 후에 다른 상품으로 이동하기 어려워지는 현상을 말합니다.
보통 스마트폰을 애플로 시작한 사람들은 애플만 계속 써요. 왜? 애플을 사용하면서 편리한 UI가 편리해서 다른 디바이스를 쓰면 복잡합니다.
그런데 저처럼 삼성폰만 쓴 사람은 삼성폰만 씁니다.
저는 옴니아부터 삼성만 썼는데 왜냐하면 삼성이 조금 UI가 복잡하긴 하지만 이미 내가 거기에 익숙해져 있어서 그 편리한 애플의 UI가 저한테는 별로 매력적이지 않은 거예요.
원래 사람은 익숙한 것을 버리지 못하지요.
그래서 첫출발이 중요한 겁니다.

이제 딥러닝을 배우기 시작하는 분들이라면 넓은 확장성과 자유도를 지원하는 PyTorch를 배우는 것도 좋을 것 같습니다.

다음은 Keras입니다.
Keras는 파이썬으로 작성된 오픈소스 신경망 라이브러리로 Tehano 또는 TensorFlow를 엔진으로 사용합니다.
Keras의 가장 큰 특징이자 장점은 모듈화인데요.
Keras에서 제공하는 모듈은 독립적이고 개발자가 원하는 대로 설정이 가능합니다.
즉, 신경망을 구성하기 위한 구성요소를 클래스로 제공하기 때문에 이를 간단하게 연결하기만 하면 쉽게 어느 누구나 신경망을 구현할 수 있습니다.
마치 레고조립처럼 말이지요.
Keras는 직관적인 API 덕분에 비전문가도 비교적 손쉽게 딥러닝 모델을 개발하고 활용할 수 있습니다.

우리가 조금 후에 2교시에서는 생성적 적대 신경망, 즉 GAN에 대해서 학습하실 텐데요.
강의 말미에 제가 Keras를 이용해서 어떻게 학습을 시킬 수 있는지 그 알고리즘을 간단하게 보여드리도록 하겠습니다.

교수님 머신러닝과 딥러닝 학습에 있어 데이터가 더 많이 필요한 영역은 무엇일까요?

정답을 먼저 말씀드리면요.
딥러닝에 더 많은 데이터가 필요하다.
이렇게 말씀을 드리겠습니다.
심층신경망은 은닉층이 많아 매개변수도 많은데요.
수백만 개에 이르는 매개변수를 훈련시키기 위해서는 정말 많은 데이터가 요구됩니다.
그림에서 보시는 바와 같이 머신러닝의 경우 어느 시점이 되면 데이터의 양과 무관하게 성능이 유지되지만 딥러닝은 계속 성능이 향상되지요.
이처럼 딥러닝은 데이터의 양과 비례해서 성능이 좋아지는데 데이터의 양과 질이 충족되어야만 좋은 성능이 나올 수 있습니다.

그럼 데이터가 턱없이 부족할 때 어떤 방법을 쓸 수 있을까요?

이처럼 학습데이터가 부족할 때 사용할 수 있는 방법으로 data augmentation이라는 기법이 있습니다.
data augmentation.
우리말로 번역하면 데이터 확장, 이렇게 말할 수 있을 텐데요.

원래 학습 데이터를 이리저리 변환해서 데이터 양을 늘리는 방법입니다.
데이터를 변환하는 방법에는 밝기나 대비를 조정하거나 이미지의 일부를 자르거나 지우거나 좌우상하의 위치를 바꾸는 회전 그리고 색깔을 바꾸는 등의 다양한 방법이 있습니다.

만약 소변검사에서 정상과 이상 이미지를 분류하기 위해서 학습을 시켜야 되는데 이 데이터가 부족하다면 어떻게 할 수 있을까요?
우리가 학습한 대로라면 원본을 회전하거나 색을 대비시키거나 일부를 잘라내서 새로운 이미지를 생성해서 학습을 시킬 수 있겠지요.

그림을 한번 보시면 여러분들이 보시는 첫 번째 그림이 원본그림이에요.
이 소변을 현미경으로 관찰했을 때 이상세포는 무엇이고 정상세포는 무엇인지를 보여주는 그림입니다.

그런데 이런 데이터가 부족하다고 했잖아요.
그래서 이 하나의 데이터를 가지고 원소스 멀티유즈를 해야 됩니다.

이를 위해서 첫 번째, 회전방법을 이용할 수 있습니다.
원본을 180도로 뒤집는 방법입니다.
옆으로 돌릴 수도 있고 위아래로 돌릴 수도 있어요.
이렇게 회전의 방법을 이용하면 또 다른 이미지가 만들어집니다.

두 번째는 원본의 색깔을 조정하는 거예요.
명도나 채도를 조정해서 색깔을 조정하면 이 또한 새로운 데이터가 됩니다.

세 번째는 자르기입니다.
전체 원본 중에 이상 데이터가 몰려있는 부분만 딱 잘라내면 이것도 하나의 새로운 데이터 세트가 되고요.

네 번째는 색깔조정으로 이렇게 자른 이미지를 색깔조정하면 이 또한 새로운 학습 데이터로 활용될 수 있습니다.

하지만 이런 변형도 정도껏 해야 합니다.
원본을 회전하고 채도를 바꾸고 일부를 잘라서 새로운 이미지를 생성해서 너무 많은 유사 이미지가 만들어지면 알고리즘은 결국 같은 데이터를 반복적으로 학습하는 것에 불과하기 때문에 이 경우에는 과적합이 일어나게 된다는 점을 유의하시기 바랍니다.

교수님. 딥러닝의 발전에 기여한 사람들을 소개해주세요.

이런 딥러닝의 발전에 기여한 사람을 꼽으라면 대부분의 사람들은 Geoffrey Hinton, Yann LeCun, Andrew Ng을 꼽을 것입니다.

Geoffrey Hinton 토론토대 교수는 현대 딥러닝 알고리즘을 완성하는 데 가장 크게 기여한 분으로 일컬어집니다.
사실 인공신경망은 1940년대에 이미 개념적으로는 개발된 방법이었고 1980년대에는 역전파라는 최적화 기법이 소개되면서 인공신경망에 대한 연구가 절정기에 이르렀는데요.
하지만 1990년대에 이르러 연구가 포화상태에 이르지만 별다른 성과가 나타나지 않으면서 암흑기가 나타나게 됩니다.
심지어 학계에서는 인공신경망이라는 키워드가 나오면 '아니 언제 적 주제인데 아직도 이런 연구를 해?' 하면서 논문을 반려했다고 합니다.
이처럼 모두가 인공신경망을 외면하던 시기에도 꿋꿋하게 인공신경망을 연구해온 학자가 바로 토론토 대학의 Geoffrey Hinton 교수인데요.
인공신경망의 한계 중에 최적화 문제가 있었는데 힌튼 교수는 2006년에 'A fast learning algorithm for deep belief nets'라는 논문을 발표하면서 훌륭한 결과를 만들어낼 수 있는 인공신경망의 최적화 방안을 제안했습니다.
이 연구는 암흑기에 놓여있던 인공지능 연구의 한 줄기 빛과 같았는데요.
이 논문을 기점으로 인공신경망 연구는 다시 중흥기를 맞게 됩니다.
특히 당시부터 활발해진 빅데이터 연구와 시너지를 내면서 학문적인 성과와 상업적인 성과를 함께 거두게 됩니다.

그의 제자들 중에는 대단히 유명한 분들이 많아요.
페이스북의 AI 랩을 이끄는 Yann LeCun 교수와 코세라 강의로 너무나 유명한 Andrew Ng 교수가 그의 제자입니다.
Andrew Ng의 페이스북에는 딥러닝 4대 천왕이 한 자리에 모인 사진을 볼 수 있는데요.
왼쪽부터 Yann LeCun, Geoffrey Hinton 교수, Yoshua Bengio, Andrew Ng, 이렇게 나와 있습니다.

이 중에 한 분 제가 설명을 안 드린 분이 Yoshua Bengio네요.
Yoshua Bengio는 몬트리올 대학의 교수로 딥러닝을 개발한 공로로 최근에 튜링상을 받은 분입니다.
앞서 언급한 GAN은 구글브레인에서 머신러닝을 연구하고 있는 Ian Goodfellow가 제안을 했는데요.
Ian Goodfellow는 Yoshua Bengio의 제자입니다.
페이스북의 Yann LeCun은 GAN을 딥러닝의 최고 핵심기술로 꼽은 바 있는데요.
상당히 재미있는 네트워크지요.





----------------------------------------------------------------------
11_03 딥러닝의 주요 모델
----------------------------------------------------------------------

[3 페이지]
다음 2교시에서는 딥러닝의 고전모델과 가장 핫한 분야로 GAN에 대해서 설명을 드리겠습니다.

먼저 딥러닝의 고전모델입니다.
1958년에 등장한 퍼셉트론으로 인공지능의 전성기가 열렸지만 1969년 마빈 민스키와 세이무어 페퍼트에 의해서 퍼셉트론의 한계가 드러나면서 인공지능의 붐이 사그라들었습니다.
그러나 1980년 네오코그니트론이 등장하고 역전파 알고리즘을 통한 학습기법이 좋은 성과를 내면서 많은 연구자들이 연구에 집중하기 시작했는데요.

오늘 수업에서는 네오코그니트론에 대해서 아주 간단하게 설명을 드리도록 하겠습니다.

네오코그니트론은 1980년대 초 일본의 후쿠시마 박사가 개발한 모델로써 7개 층을 가진 인공지능 모델입니다.
보시는 바와 같이 모델이 매우 정교하지만 학습시간이 너무 오래 걸린다는 단점이 있었습니다.

일례로 한 글자를 인식하는 데 무려 20분 정도가 걸렸다고 하는데 그 당시 하드웨어의 성능을 보면 너무나 당연한 일로 보입니다.
이후 딥러닝은 급격한 진화를 거치게 되는데 대표적으로 RBM 모델이라는 게 있습니다.

2006년 토론토 대학의 힌튼 교수가 딥러닝 학습방법을 발표했는데 그는 다층 신경망에 학습을 통한 전처리 과정을 추가했습니다.
힌튼이 제안한 새로운 알고리즘 RBM은 Restricted, Boltzmann, Machine의 약자로써 우리말로 쓰면 제한, 볼트만, 머신, 이렇게 쓸 수 있을 것 같아요.
Restricted, 제한된, Boltzmann, 볼츠만, Machine, 머신.
그대로 옮기니까 제한 볼츠만 머신이 되는데 이것은 처음부터 가중치를 정교하게 해주는 방법입니다.

즉, RBM은 초기값을 랜덤으로 주는 게 아니라 제대로 주면 성능이 좋아질 거라는 가설에서 탄생했는데요.
앞으로 계산한 값과 거꾸로 계산한 값의 차이를 줄이는 목적으로 가중치를 업데이트하여 처음부터 가중치를 최적화한 후에 모델을 정교화하는 방식을 취한다고 이해하시면 되겠습니다.

처음 들어보니까 좀 생소하시죠?
왜냐하면 이게 여러분 역전파를 배우지 않으셔서 이해가 더 안 될 텐데 제가 아주 간단한 사례를 가지고 다시 한번 설명을 드려보겠습니다.

그림을 먼저 좀 봐주시겠어요?
그림을 보면 이렇게 모델이 나와 있지요.
먼저 X1에는 2, X2에는 1이라고 하고요.
4개의 가중치를 1, 1, 2, -1로 임의로 지정해 보겠습니다.
왜냐하면 옛날에는 가중치를 정교화해서 설계한 게 아니라 연구자가 내 마음대로 그냥 설정을 했거든요.
여기서도 마찬가지로 제가 그냥 마음대로 1, 1, 2, -1로 가중치를 임의로 지정해 보겠습니다.
그러고 나서 X와 각 가중치의 곱을 더한 가중합의 값을 계산했더니 뭐와 뭐가 나오죠? 4와 1이 나오지요.

이러한 알고리즘이 작동한 신경망이 작동한 결과값으로 4와 1이 나왔습니다.
그런데 제대로 된 모델이라면 앞으로 계산하든 뒤로 계산하든 똑같은 결과값이 나와야 돼요.
1, 4를 넣어서 4, 1이 나왔고, 4, 1을 역산하면 다시 1, 4가 나와야 되는데 그렇게 되는지 한번 보도록 하겠습니다.
이제 결과값인 4와 1과 가중치값을 역산해보겠습니다.
그랬더니 2와 1이 아닌 5와 7이 나오지요.
앞으로 계산한 것과 역산한 경우 A와 X'값이 완전히 다르게 나왔습니다.

이 문제를 해결하기 위해서 가중치를 조금씩 수정해나가다 보면 X와 X'를 같게 만드는 가중치를 얻을 수 있는데요.
이 경우에 가중치를 1, 0.5, -1로 가정했더니, 설정했더니 앞으로 계산하나 역산하나 같은 값이 나오는 겁니다.

이 경우에 가장 최적화된 가중치는 1과 0.5와 -1과 1이 되는 거지요. 이처럼 좀 더 정확한 가중치를 두면 모델을 쉽게 발전시켜나갈 수 있습니다.

이 과정을 출력층까지 진행하면서 가중치의 초기값을 찾는 방식이 바로 앞서 말씀드린 RBM이에요.
앞서 머신러닝에서의 학습은 가장 정확한 가중치를 찾는 것이라고 말씀을 드렸지요.

초기에 정확하게 가중치를 설정하는 RBM은 딥러닝의 발전에 크게 기여했습니다.
힌튼은 일찍이 딥러닝의 성능 문제로 다음을 언급한 바 있습니다.
RBM은 이 문제를 효과적으로 해결하였지요.

힌튼이 제기한 문제를 힌튼 스스로가 해결한 겁니다.
그 후에는 드롭 아웃이라는 알고리즘이 과적합 문제를 해결하면서 기능적으로 큰 성능을 보이기 시작했는데요.

드롭 아웃은 말 그대로 드롭 아웃, 뭔가를 떨어뜨려서 내보낸다는 뜻입니다.
즉, 은닉층에 배치된 노드 중 일부를 임의로 삭제해주는 방법으로 앞서 말씀드린 multi-task learning과 함께 과적합을 줄여주고 정규화를 지원하는 기법입니다.

다음에서는 생성적 적대 신경망의 알고리즘에 대해서 구체적으로 살펴보겠습니다.
생성적 적대 신경망은 이미지의 진위를 판단하는 판별자 알고리즘과 가짜 이미지를 만들어내는 생성자 알고리즘을 대립시켜서 영상을 조작하는 원리입니다.
즉, 생성적 적대 신경망은 생성망과 판별망이라는 2개의 네트워크로 구성이 되는데 생성망이 데이터를 만들면 판별망이 데이터가 진짜인지 가짜인지를 판단하는 역할을 해줍니다.

이들 간의 대립을 통해 원본과 조작영상물의 오차를 최대한 줄여나가는 방식으로 조작된 영상물의 완성도를 높여 나가는데요.
이런 생성적 적대 신경망을 앞 글자를 따서 GAN이라고 부르겠습니다.

앞서 GAN은 2014년 이안 굿펠로우 등이 발표했다고 말씀드렸는데 현재 가장 많은 연구가 이루어지고 있는 아주 핫한 분야입니다.

다음에서는 이 생성적 적대 신경망을 이용해서 새로운 이미지를 만들어내는 사이트의 사례를 살펴보도록 하겠습니다.
GAN과 관련된 연관검색어를 쳐보면 ThisPersonDoesNotExist.com이라는 사이트가 검색이 됩니다.

'이 사람은 존재하지 않는다'라는 이름을 가지고 있는데요.
여기서는 생성망과 판별망의 경쟁을 통해서 만들어진 새로운 데이터를 확인할 수 있습니다. 생성망은 수많은 얼굴 데이터를 학습한 후에 사람의 얼굴과 비슷한 가짜 이미지를 만듭니다.

그러면 판별망은 생성망이 만든 얼굴 이미지가 진짜인지를 판단하는데요.
여기서 적대적이라는 표현이 들어간 이유는 생성망과 판별망이 서로 적대적인 관계에서 경쟁을 하고 있기 때문입니다.

이렇게 생성망과 판별망이 경쟁하면서 점점 그럴듯한 얼굴이 만들어지는데요.
나중에는 사람이 구별하기 힘들 정도로 진짜 같은 얼굴을 만들어주게 됩니다.
이 그림이 바로 생성적 적대 신경망, 즉 GAN을 통해 만들어진 가상의 인물이었지요.

어떻습니까?
이런 얼굴을 가진 사람이 지구 어디엔가 있을 것 같지 않나요?

다음 이미지는 미국의 인기 코미디언이자 배우인 Bill Hader 얼굴이 몇 초 후에 Arnold Schwarzenegger로 바뀌는 딥페이스 영상입니다.
여기서도 진짜 감쪽같지요.
합성하고자 하는 2명의 얼굴이 있는데 얼굴의 모습이나 표정이 다르더라도 알아서 자연스럽게 합성을 해주기 때문에 사람들은 이 이미지에 쉽게 속게 됩니다.

이런 기술이 꼭 범죄에만 이용이 될까요?
꼭 그렇지는 않습니다.
GAN을 이용하면 자율주행자동차의 학습과 검증에 사용되는 합성데이터를 만들 수 있습니다.

자율주행자동차의 성능을 높이기 위해서는 그만큼 학습 데이터가 많이 필요한데 데이터를 모으는 일에는 엄청난 인력과 시간이 투입되어야 합니다.
이때 GAN을 이용해서 실제와 거의 유사한 합성데이터를 만들어내고 이것으로 훈련을 시킨다면 부족한 데이터 문제를 해결할 수 있겠지요.

중요한 건 동기와 의도입니다.
아무리 좋은 기술도 나쁜 목적으로 쓴다면 나쁜 결과를 가져올 것이며 이런 좋은 기술을 인공지능의 선한 방향으로 사용이 된다고 하면 우리에게 다양한 효익을 제공할 겁니다.

GAN을 설명하기 위해서 가장 많이 언급하는 화폐의 위조범과 경찰 사례를 한번 들어보도록 하겠습니다.
위조범이 만든 가짜 화폐를 경찰이 단속합니다.
그러면 화폐 위조범은 더욱 정교하게 가짜 화폐를 만들어냅니다.
경찰도 더욱 고도화된 수사기법으로 가짜 화폐를 적발해냅니다.
이처럼 둘은 쫓고 쫓기는 경쟁을 하고 이 과정에서 가짜 화폐는 점점 고도화됩니다.

이를 알고리즘으로 나타내면 다음과 같습니다.
이 그림에서 위조 지폐범과 지폐 판별사는 각각 2개의 독립적인 신경망 모델입니다.
이런 2개의 신경망 모델이 서로 주고받으면서 경쟁을 하면서 위조기술이 향상되는 식입니다.

지폐감별사는 가짜를 진짜로 판별하는 실수를 최소화하는 방식으로 자신의 능력을 향상시키고 반대로 위조 지폐범은 가짜를 진짜로 판별하는 실수를 최대화하는 방식으로 자신의 능력을 향상시켜 나갑니다.
이렇게 서로 경쟁을 하다 보면 결국 위조 지폐범의 능력이 극대화되어서 지폐 감별사가 감별하기 어려운 거의 완벽한 수준의 위조지폐가 만들어지는 겁니다.

아래에서는 미니스트의 손글씨 데이터셋과 생성망에서 만들어진 가짜 데이터를 판별하면서 학습을 진행하는 딥러닝 모델을 보여주고 있는데요.
이를 Keras로 훈련하기 위해서 다음과 같은 코드를 이용할 수 있습니다.

코드 한 번 잠깐 보실까요?
어떻습니까? 생각보다 코드가 되게 단순하지요.
간단하게 코드를 짜도 정교하게 작동이 될 수 있다는 것이 최근 인공지능 오픈소스 라이브러리의 특징이며 이러한 집단지성 덕분에 인공지능이 발전하고 있는 것입니다.

한 개의 사이트를 하나 더 볼게요.
이 사이트의 이름은 generated.photos입니다.
이것도 보면 사진을 생성해낸다는 감이 오지요.
이것은 GAN을 이용해서 합성 이미지를 생성해서 제공하는 무료 이용 사이트입니다.
해당 사이트에서 제공하는 사진들은 인공지능이 만든 이미지로 저작권이나 초상권 침해, 로열티에 대한 걱정 없이 다양한 사진을 무료로 이용할 수 있도록 합니다.
그렇다면 이 사이트는 우리에게 어떤 가치를 제공할까요?
이런 서비스를 무료로 제공함으로써 해당 사이트는 어떤 이점을 취할 수 있을까요?
먼저 이들이 제공하는 무료 이미지로 많은 사람들이 혜택을 볼 수 있을 것 같습니다.
당장 저만 하더라도 강의교안을 개발해야 할 때 인물사진이 필요한데 그런 인물사진을 쓰려면 저작권 때문에 아무 거나 갖다 쓸 수 없거든요.
그리고 또 그런 사진을 쓰더라도 밑에 출처정보를 달아야 하기 때문에 강의교안이 조금 지저분해집니다.
그런데 제가 아이가 필요하면 아이 사진을 갖다 써도 되고 남성이 필요하면 남성 사진을 갖다 써도 되기 때문에 이처럼 인물사진을 무료로 사용할 수 있으면 너무 좋을 것 같아요.

저처럼 강의교안을 만들거나 쇼핑몰을 개발하거나 아니면 파워포인트 자료로 PT 자료를 만들 때 이런 이미지를 사용하면 상당히 좋겠지요.
이처럼 많은 사람들이 해당 사이트가 생성하는 사진을 많이 이용하면 그만큼 해당 기업과 기술의 가치는 높아질 겁니다.
이 기업이 만약 스타트업이라면 비싼 금액으로 구글 같은 글로벌 기업에 인수합병을 당할 수 있을 겁니다.
제가 인수합병을 당한다고 표현했지만 사실은 성공적으로 기업을 매각할 수 있는 지름길이 되는 거지요.

교수님 가짜 이미지 제작 기술은 오래 전부터 있어 왔는데 뭐가 그렇게 대단하다고 하는 것일까요?

네. 맞습니다.
가짜 이미지 제작 기술은 사실 이미 오래 전부터 있어 왔어요.

하지만 과거 이미지는 하나하나 수작업으로 편집되었기 때문에 한 눈에 봐도 조작한 티가 확 나고요.
이미지를 확대하면 조작한 티가 더욱 확실하게 나타났습니다.

그런데 영상편집 기술이 인공지능 기술인 GAN과 만나면서 진짜와 가짜를 감별해내기 어려울 정도로 조작이 정교화된 거지요.
이처럼 딥러닝 기술이 놀라운 속도로 진화되고 있지만 딥러닝 기술이 인간 뇌의 성능을 따라오려면 아직 멀었다고 봅니다.

인간의 시각 피질은 고작 몇 백g밖에 안 되고 한 끼 식사면 몇 시간이고 우리의 머리가 팍팍 돌아가지만 기계가 그 일을 하려면 엄청난 스펙의 컴퓨터와 컴퓨팅 파워가 필요합니다.

알고리즘의 성능개선을 위해서 접근하는 각종 시도도 인간 뇌세포의 작동방식과 전혀 관련이 없고 이 방법을 사용하면 어떻게 성능이 나아지는지에 관한 이론적 근거도 명확하지 않은 경우가 많습니다.

의학분야의 전문지식을 공학분야의 지식으로 설명하는 데 분명히 한계가 있겠지요.
여러 가지 시행착오 끝에 학습이 잘 되는 방법을 찾았을 뿐 이는 인간의 뇌 작동방법과 무관한 경우가 많다는 겁니다.

딥러닝의 경우 어떤 결과가 나타나는 이유를 설명하기가 어려운 경우가 꽤 많아요.
인공신경망 내부는 복잡한 파라미터로 구성되어 있기 때문에 알고리즘의 결정을 이해하고 설명하고 평가하는 것은 상당히 어렵습니다.

이는 곧 인공지능의 성능, 특히 딥러닝의 성능에 대한 공식적인 보증이 어려움을 의미하는데요.
이러한 문제점을 하나하나 해결해나가는 가운데 인공지능도 발전하겠지요.

우리가 딥러닝 알고리즘을 개발하기 위해서 우리가 반드시 거쳐야 되는 필수과정이 있습니다.
한 5가지 정도로 정리해서 살펴보면

첫 번째는 충분한 학습데이터를 확보하라입니다.
공개데이터를 쓰든 직접 모으든 모은 데이터를 회전하고 잘라서 복제하든 충분한 학습 데이터를 모으라는 게 중요하고요.

두 번째 단계는 딥러닝 알고리즘을 개발하라는 겁니다.
이때 우리가 반드시 고려해야 될 것은 최대한 간단하게 지나친 아웃라이어는 고려하지 말고 이와 관련해서 제가 몇 가지의 원칙, 법칙도 설명을 드렸지요.

세 번째는 딥러닝 신경망을 충분히 학습시켜라입니다.
여기서의 포인트는 뭐다? 과적합이 오지 않을 정도로 충분하게 학습을 시키라는 거고요.

그다음 네 번째 단계는 딥러닝 신경망을 평가하라입니다.
이때 우리가 주의해야 될 사항은 뭐였죠?
훈련 데이터와 평가 데이터를 완벽하게 분리하라고 말씀을 드렸고 이런 훈련 데이터와 평가 데이터는 7:3 또는 8:2 정도가 적정하며 이런 데이터를 가지고 올 때 여기저기서 끌어오지 말고 하나의 원소스에서 데이터를 통으로 가져오라고 설명을 드린 바 있었습니다.

마지막 다섯 번째는 완성된 딥러닝 신경망으로 예측하고 판단하라입니다.
다만 이 기술이 성과를 낼 수 있는 분야를 잘 골라서 그런 분야 먼저 딥러닝 신경망을 적용하는 것이 작은 노력으로 많은 성과를 낼 수 있는 바람직한 전략이라고 생각됩니다.
