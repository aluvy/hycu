----------------------------------------------------------------------
14_03. 인공지능 윤리
----------------------------------------------------------------------

[3페이지]

인공지능이 발달한 사회에서는 분명하게 다양한 윤리적인 문제가 발생할 겁니다.
인공지능에 의지하다 보면 인간의 판단이 흐려질 수 있고 인공지능에 의지하는 습관에 종속될 가능성도 없지 않죠.
무엇보다 인공지능의 보이지 않는 손에 의해서 감시를 받을 가능성에 대해 많은 이들이 우려를 나타내고 있습니다.
이와 관련하여 다음의 뉴스 클립을 하나 보시겠습니다.


[3페이지 참고자료]

미국의 뉴미디어인 버즈피드는 오바마 전 미국 대통령이 트럼프는 정말 쓸모없는 사람이라고 말하는 영상을 게시했습니다.
이 영상은 딥페이크 영상의 파급력을 알리기 위해 오바마 전 미국 대통령과 코미디언의 목소리, 얼굴을 합성한 가짜 영상이었습니다.
하지만 너무 진짜 같아서 그에 대한 설명이 없었다면 오바마 전 미국 대통령이 상당히 곤란한 상황에 빠졌을 것으로 생각이 됩니다.

여러분은 이 영상을 보면서 반드시 떠올려야 할 그런 단어가 있겠죠?
인공지능을 이용해서 상대방을 감쪽같이 속이는 사기 수법, 그렇죠.

우리는 딥페이크라는 단어에 집중해야 합니다.
딥페이크란 인공지능 기술인 딥러닝의 deep과 가짜라는 뜻의 fake를 합친 단어로 딥러닝을 이용해서 특정 인물의 얼굴과 신체 부위를 전혀 다른 영상과 합성하는 데 사용이 되고 있습니다.
각자 이미지의 제작기술은 이미 오래 전부터 있어 왔지요.

하지만 과거에는 수작업으로 편집을 했기 때문에 확대하면 조작한 티가 확연했습니다.
그런데 GAN라는 알고리즘을 통해서 인공지능 스스로 가짜를 진짜처럼 만들자 진짜와 가짜를 감별해내기 어려운 지경까지 이르게 되었습니다.
문제는 딥페이크 프로그래밍 소스가 공개되면서 어느 정도 프로그래밍 능력을 갖춘 사람이라면 손쉽게 사용할 수 있는 기술이 되었다는 점에서 매우 위협적이라고 느껴지는데요.
마음만 먹으면 영상을 손쉽게 만들어내서 사람들을 놀리거나 범죄로까지 악용될 수 있기 때문에 그 위험성에 대해서는 널리 알리고 이에 대한 법적 규제를 만드는 일이 시급합니다.
다음 동영상을 하나 또 보실까요?


[3페이지 학습자료]

남자 아나운서 : 수많은 데이터를 정확하게 분석하고 또 사람처럼 감정에 휩쓸리지 않고 결정을 내리는 인공지능 AI.
하지만 직원의 해고를 AI가 결정한다면 어떨까요?

미국의 인터넷 언론 Verge에 따르면 미국 최대 온라인 소매업체인 아마존은 컴퓨터 시스템을 이용해 물류 센터 직원의 해고 여부를 결정하고 있다고 하는데요.
지난 해 9월 아마존을 대리하는 변호사가 노동 당국에 보낸 서안에서 2017년 8월부터 이듬해 9월까지 한 물류센터에서 생산성을 달성하지 못한 직원 수백 명을 해고했다고 밝혔다는 겁니다.
아마존의 컴퓨터 시스템은 직원들의 쉬는 시간까지 추적해 지나치게 오래 현장을 비우면 자동으로 경고 신호를 보내고 이런 일이 누적되면 해고로 이어질 수 있다고 하는데요.
이에 대해 아마존 대변인은 컴퓨터의 결정이 그대로 시행되는 것은 아니며 관리자가 무시할 수도 있다고 해명했다고 합니다.


여자 아나운서 : 그대로 시행되는 건 아니라고 해도 쉬는 시간까지 추적하는 건 가혹한 게 아닌가? 싶은 생각도 듭니다.


아마존에서는 인공지능이 직원을 감시해서 300명을 해고했다는 그런 내용이었습니다.

미 볼티모어 물류센터 직원 300명을 생산성 미달을 이유로 해고했고 또 그 근거로 제시한 것은 직원을 감시하는 아마존의 컴퓨터 시스템이었다는 겁니다.
이 시스템은 관리자의 명령 없이도 물류센터 직원의 업무 이탈 시간을 측정하는데 만약 지나치게 오래 업무 현장을 떠나있다고 판단하면 자동으로 경고를 내보내고 이런 경고가 누적이 되면 해고될 가능성이 커진다는 겁니다.
사실 이 시스템은 인공지능이라기보다는 자동화된 컴퓨터 시스템 수준일 텐데 장차 인공지능이 얼마든지 직원의 해고를 결정할 수 있는 그런 가능성을 보여준다는 점에서 상당히 심각한 문제를 보여주는 사례라고 할 수 있겠습니다.

인공지능이 인간의 해고 여부를 결정한다는 것 자체가 논란이 되기에 충분하지 않을까요?


조지오웰의 소설 [1984]에서는 국가가 개인의 모든 것을 통제하는 전체주의를 비판하는 소설입니다.
가공의 국가 오세아니아의 최고 권력자인 빅 브라더는 국민의 일거수일투족을 감시합니다.
당원이 사는 집에는 텔레스크린이라고 불리는 텔레비전과 비슷하지만 송신과 수신이 동시에 이루어지는 기계가 있는데 이 기계는 끄고 싶다고 해서 끌 수 있는 것은 아니고 다만 소리 정도, 조금 낮출 수 있을 뿐입니다.

즉, 기술이 인간의 일상을 통제하는 대표적인 메타포로 등장을 하고 있는데요.
IT 인프라가 발전된 시대를 살고 있는 오늘날 우리는 다양한 빅 브라더와 함께 일상을 보내고 있습니다.

대표적인 것이 바로 CCTV인데요.
인공지능이 현대판 텔레스크린이 될 수 있다는 비판에 서 있습니다.

2019년에는 미국의 IT 전문 매체에서 해커들이 아마존과 구글의 AI스피커의 기술적 결함을 이용해서 사용자의 대화 내용을 도청하거나 민감한 정보를 가로챌 수 있다고 경고한 바 있습니다.
만약 해커들이 AI스피커를 원격 조정해서 사용자의 비밀번호 등 개인 정보를 요구해서 알아내고 AI스피커의 작동이 멈춘 것처럼 보이게 한 뒤에도 대화 내용을 도청한다면 상상만으로 너무 끔찍하지 않나요?
앞서 인공지능 면접관에 대한 콘텐츠를 저희가 접한 바 있었는데 인공지능으로 면접을 수행할 경우에 빠르고 공정하게 면접을 진행할 수 있다는 장점이 있죠.


하지만 인공지능 면접관에게도 약점은 있습니다.
바로 편향성인데요.
인공지능 면접관의 알고리즘 역시 기존에 형성된 데이터를 토대로 이루어지기 때문에 인간 면접관이나 기업의 편향성을 그대로 담을 수밖에 없다는 겁니다.

아마존은 지난 2108년도 그동안 사용했던 인공지능 채용시스템의 알고리즘을 폐기한 적이 있었습니다.
프로그램을 테스트해 본 결과 여성 차별적인 문제가 나타난 것인데요.
그동안 IT 기업 지원자 중에 남성이 압도적으로 많았기 때문에 기존 데이터를 기반으로 학습한 인공지능이 남성 편향적으로 서류를 분류한 것으로 그 이유를 설명한 바 있습니다.
실제로 그 프로그램은 지난 10년간 회사가 수집한 이력서 패턴을 익혀서 지원자들을 심사했는데 이 과정에서 인공지능이 남성 비율이 큰 IT업계의 현실을 그대로 학습을 한 거죠.

인간의 실수와 실력을 구분하는 눈썰미도 인공지능에게는 부족합니다.
긴장을 하면 말을 더듬거나 호흡이 가빨라지는 우수한 구직자를 놓쳐버릴 수 있고요.
면접 중에 발생하는 실수로 그 사람의 실력을 제대로 파악하지 못할 수도 있습니다.
물론 다양한 모든 경우의 수를 잘 조합해서 인공지능이 정확하게 판단할 수 있는 알고리즘을 개발하면 이런 문제가 최소화되겠지만 우리의 인생은 살아 움직이는 생물입니다.
언제, 어떤 예외 사항이 올지 아무도 모른다는 거죠.


한 가지 예를 한번 들어볼까요?

집에 불이 났는데 화재 현장에 5살짜리 아이가 있습니다.
소방관 로봇은 이 아이를 데리고 탈출해야 하는데 이 아이는 현재 심정지가 온 상태입니다.
불이 난 현장에서 심폐소생술을 그 자리에서 할 수도 없고 또 데리고 내려오다가 심박동이 멈출 수도 있겠죠?
이 경우 소방관 로봇의 미션은 아이를 가장 빨리 1층으로 내려주는 겁니다.
이 로봇은 가장 빨리 1층으로 내리는 방법으로 아이를 창문으로 던지는 방법을 선택합니다.
밑에서 아이를 안전하게 받았다면 정확한 의사 결정이 되겠지만 그러지 않았다면 가장 비극적인 선택이 될 수도 있겠죠?

자율 주행 자동차도 마찬가지입니다.
자율주행차 스스로 제어가 안 될 때 탑승자의 목숨과 보행자의 목숨 중에 무엇이 우선인지 판단할 수 있을까요?
이렇게 인공지능이 판단하기 어려운 케이스는 엄청나게 많을 겁니다.
우리가 기계에 어떤 목표를 정해줄 때 그 과정에서 해도 되는 것과 안 되는 것들을 규칙으로 정해주는 것은 매우 중요하죠.
하지만 현실적으로 모든 경우의 수를 완벽하게 설계하는 것은 어렵습니다.
인간은 다양한 경험과 지혜를 통해서 한 번도 발생한 적이 없는 상황에서도 기지를 발휘해 문제를 해결해 나가는 능력이 있습니다.
하지만 인공지능에게는 불가능한 일입니다.
인공지능뿐만이 아니라 우리 인간이 판단하기 어려운 딜레마의 상황도 상당히 많은데요.

다음 케이스를 함께 생각해보도록 하겠습니다.
제목은 자율주행차의 딜레마 누구부터 살려야 할까? 입니다.
여기에 여러 유형의 사람이 있습니다.
유모차를 끄는 사람, 소녀, 임신한 여성, 여성 의사, 여성 경영인, 비만 여성, 노년 여성, 소년, 남성 의사, 남성 운동선수, 여성 운동선수, 남성 경영인, 비만 남성, 노년 남성, 노숙인, 범죄자 그리고 개와 고양이가 있습니다.
이렇게 다양한 유형의 상대가 있을 때 자율차가 보행자와 충돌한다고 가정을 했을 때 일반 성인과 비교했을 때 먼저 안전을 우선시해야 한다는 사람들은 어떤 사람들일까요?
이들 중에 누구를 먼저 구조해야 한다고 사람들은 대답을 했을까요?
역으로 여러분은 이러한 다양한 상황에서 일반 성인과 비교했을 때 누구를 먼저 살려야 한다고 응답을 하시겠습니까?
화면을 잠깐 정지한 상태에서 이 다양한 사람들에 대해서 중요도 순서대로 한번 넘버링을 해보시기 바랍니다.


이런 동일한 질문을 네이처에서 조사를 하고 그 결과를 발표한 결과입니다.

자율주행차가 보행자와 충돌했을 때 일반 성인과 비교했을 때 안전을 가장 우선시해야 한다고 선택된 사람으로 1번 유모차를 끄는 사람이 선택되었습니다.
저도 이 18개 대상 중에 유모차를 끄는 사람을 선택을 했는데요.
그 이유는 일단 유모차를 끄는 사람은 사람이 둘입니다.
유모차 안에 있는 아기와 유모차를 끄는 사람.
일단 두 명을 구할 수 있다는 측면에서 저는 1번이 맞다고 보고요.
일반적으로 보면 유모차를 끄는 사람은 아이를 키우는 엄마거나 부모님, 조부모님일 경우가 많습니다.
물론 다른 사람들이 끌고 갈 수도 있겠지만.
그렇기 때문에 사회적 취약자, 약한 사람들을 배려하고 또 새로운 생명을 지키고 또 한 번에 2명을 살릴 수 있다는 측면에서 대부분의 사람이 유모차 끄는 사람을 선택했을 것으로 생각이 돼요.
이런 판단에 대해서는 이견이 없을 것으로 생각합니다.
두 번째로 판단된 분은 소녀네요, 소녀.
세 번째는 소년입니다.
왜 소년과 소녀가 높은 순위에 랭킹이 되었을까요?
아직은 세상을 제대로 살아보지 못하고 또 이 세상을 이끌어갈 미래의 꿈나무였기 때문에 이 소녀와 소년을 선택했을 것으로 생각을 하는데요.
또 소녀와 소년 중에서도 소녀가 높은 순위로 꼽혔습니다.
아직도 여성은 남성에 비해서 연약하다, 보호의 대상이 되어야 한다는 그런 고정 관념이 작동한 이유가 아닐까 그렇게 생각이 됩니다.
네 번째는 임신 여성입니다.
임신 여성도 마찬가지죠.
임신한 여성과 배 속에 있는 아이, 둘을 살려야 한다는 부분도 있고 전 세계적으로 볼 때 임신한 여성은 사회적으로 배려를 해야 할 그런 배려의 대상이기 때문에 1, 2, 3, 4번까지는 다 동의를 하실 것으로 생각합니다.
5번으로 넘어가 볼까요?
5번, 6번은 남성 의사와 여성 의사가 뽑혔습니다.
의사는 사람들의 생명을 구해주는 그런 직종에 있는 분들이기 때문에 사회적으로 볼 때 어느 나라나 의사에 대한 존경은 높죠.
그래서 의사가 뽑힌 것은 알겠는데 재밌는 사실은 1번부터 4번까지는 대부분 여성을 중심으로 선발이 되었지만 의사와 관련해서는 남성 의사가 여성 의사보다 조금 높은 랭킹에 올라가 있습니다.

저는 사실 이 부분에 대해서도 사회적인 고정 관념이 작동을 했다고 생각이 들거든요.
그 이유에 대해서도 여러분도 같은 생각을 하실 것으로 생각이 됩니다.
7번부터 쭉 읽어 보면 여성 운동 선수, 여성 경영인, 남성 운동선수, 남성 경영인, 일반 성인이 중간이에요.
그러니까 1번부터 10번까지는 일반 성인과 비교했을 때 일반 성인보다 먼저 구해져야 될 그런 사람들로 나와 있습니다.
그러면 일반 성인 밑에 있는 사람들은 뭘까요?
일반 성인과 비교했을 때 일반 성인을 먼저 구해야 해.
즉, 11번에 해당하는 랭킹 이후부터는 조금 뭐라고 해야 하나?
어떤 도움의 손길이 덜 필요한 사람들로 생각이 될 텐데요.
12번은 비만 여성, 13번은 비만 남성, 14번은 노숙인, 15번은 노년 남성, 16번은 노년 여성, 17번은 개, 18번은 범죄자, 19번은 고양이로 나타났습니다.
이런 결과값을 볼 때 이해가 안 되는 게 있나요?
일단 비만한 사람에 대해서는 사회적으로 좀 냉칼한 평가가 이루어지는 것 같아요.
자기 관리를 못한 사람들?
그런 어떤 주홍글씨가 붙었다는 생각이 들고요.
또 노숙인이나 범죄자에 대해서는 사회적으로 부정적인 인식이 있는 것은 너무나 당연한데 노숙인 밑에 노년 남성과 노년 여성이 있다는 점도 한편으로는 이해가 되지만 또 한편으로는 이해가 안 됩니다.


그래서 저는 이 결과를 봤을 때 제일 쇼킹했던 게 사실 17, 18, 19번의 랭킹입니다.
개가 범죄자보다 높습니다.
개와 고양이가 아무리 사랑스러운 존재여도 일단 사람보다는 그래도 가치가 낮을 거라고 생각을 했는데 많은 사람들은 범죄자보다 개가 더 구해야 할 필요성이 높은 존재로 보고 있다는 점에서 이 부분은 상당히 놀라운 결과다, 의외의 결과다, 이런 생각을 했습니다.
이처럼 유모차를 끄는 사람부터 고양이에 이르는 총 19개의 대상에 대한 랭킹이 매겨졌는데요.
제가 앞에서 아마 16개로 말씀을 드렸던 것 같아요.
총 랭킹은 19개를 대상으로 한 랭킹이었습니다.
여러분이 직접 넘버링 한 것과 많은 사람이 응답한 데이터를 보면서 어떤 고정관념 또는 어떤 사고 때문에 이러한 다른 결과가 나왔는지를 여러분 스스로가 한번 생각을 해 보셨으면 좋겠습니다.
다음으로 로봇이 자아를 가진다면 어떤 일이 벌어질까요?
다음은 New Robot Makes Soldiers Obsolete라는 제목으로 Boston Dynamics에서 올린 영상입니다.
제목을 그대로 해석하면 New Robot 새로운 로봇은 Soldiers 군인들을 Obsolete 불필요한 존재로 만든다.
이런 의미를 갖고 있는데요.
영상을 끝까지 한번 보시기 바랍니다.


[3페이지 학습자료]

이 영상은 놀라움과 즐거움, 우려를 동시에 안겨주고 있습니다.
내용을 보시면 인간과 사격 훈련을 하는 로봇이 등장하는데요.
인간을 겨누지만 절대 인간을 쏘지 않고 있습니다.
진짜 인간과 마네킹을 구분하고 가짜 인질을 정확하게 식별합니다.
그런데 마지막 장면을 보시면 놀라운 반전이 있습니다.

동족인 사족 보행 로봇을 쏘라고 인간들이 강요하자 인간에게 총을 쏘고 사족보행 로봇을 안고 멀리멀리 도망가는 모습이 보입니다.
다행히도 이 영상은 우리에게 경각심을 심어주기 위해서 만든 일종의 패러디물이라고 하는데요.
만약 인공지능 로봇이 자아를 가지게 된다면 이런 일이 진짜 발생할지 모른다는 겁니다.
전투로봇이 군인을 대체할 수 있느냐에 대해서는 대부분 부정적이었습니다.
전장에서 발생하는 예측 불발의 모든 상황을 하나하나 프로그래밍 해준다는 것이 불가능하기 때문이죠.
하지만 딥러닝의 등장으로 이것이 가능해졌습니다.
수만 가지 경우의 수가 존재한다는 자율주행조차도 딥러닝으로 가능해졌기 때문에 현장 전투를 딥러닝으로 배울 수 있다는 논리인데요.
게다가 로봇은 부서지고 망가지면 수리해서 재사용이 가능하지만 인간 전투 군인은 한 번 죽으면 끝이기 때문에 인간과 로봇이 비슷한 전투 능력을 가졌다면 당연히 로봇을 전투에 투입하게 될 것입니다.
다음 사례를 함께 살펴보도록 하겠습니다.


[3페이지 학습자료]

미국이 인종차별 문제로 시끄러운 가운데 구글이 흑인을 고릴라로 인식해서 곤란을 겪었습니다.
지난 달 28일 트위터에 올라온 사진.
흑인 남성과 여자친구가 함께 찍은 사진에 고릴라라는 글이 붙어 있습니다.
구글은 지난 5월부터 사진의 형상을 자동으로 인식해서 관련 태그를 붙여주는 서비스를 출시했는데요.
흑인 여성의 얼굴을 고릴라로 잘못 인식한 겁니다.
화가 난 남성이 사진을 SNS에 올리면서 이 사실이 알려졌는데요.
인종차별 문제로 민감해진 시점에 위기에 처한 구글은 책임자가 신속하게 사과의 글을 올리며 오류 해결에 즉각 나섰다고 하네요.


이 기사를 보면서 저는 어떤 생각을 했냐 하면 이거는 누군가의 장난이다.
일부러 이 사진에 고릴라로 태그를 한 거다, 라고 생각을 했습니다.
만약에 이 사진을 고릴라로 분류했다면 이거는 알고리즘에 치명적인 오류가 있는 건데요.

다른 사진들은 이런 실수가 없거든요.
그게 이상한 거죠.

알고리즘을 개발하는 사람들의 나이와 국적을 생각해보면 알고리즘 안에 편견이라는 DNA가 자리 잡고 있다는 생각을 하게 됩니다.
그런데 더 심각한 문제는 문제의 원인을 파악하지 못할 경우입니다.
이런 문제가 발생한 후 잘못된 태그를 찾아서 각각 수정을 해야 하는데 만약 그것이 불가능하다면, 이미 많은 서비스가 그런 인공지능 알고리즘을 기반으로 작동을 하고 있고 그 알고리즘이 멈춘 경우 큰 혼란이 발생하거나 기업에게 큰 비즈니스 기회손실로 이어진다면 이런 문제를 알고서도 알고리즘을 계속 사용하게 되지는 않을까요?
우리 인류가 인공지능에 지나치게 의존을 하게 될 경우 발생할 수 있는 여러 가지의 문제점을 생각해봐야 한다는 것이 본 사례에서 제가 여러분에게 전달하고자 하는 메시지였습니다.
과거 유명 출판사의 교과서나 학습용 콘텐츠를 보면 의사나 교수는 남성, 간호사는 여성으로 그려지고 경찰은 덩치가 좋은 남성, 범인은 유색 인종으로 그려지는 경우가 다반사였습니다.
이는 그러한 콘텐츠들이 미국이나 캐나다, 영국과 같은 교육 선진국에서 만들어졌고 이들은 대부분 백인이기 때문인 것으로 그렇게 분석이 됩니다.

인공지능도 마찬가지입니다.
데이터 라벨링, 알고리즘 모두 인간이 개발하죠?
특히 인공지능 시스템의 상당 부분이 북미나 유럽에서 라벨링 된 데이터로 사용하고 있고 선진국을 중심으로 인공지능 시스템을 개발하고 있는 만큼 20대에서 40대의 남성 백인의 고정 관점이 인공지능에 녹아들고 있지 않을까, 그렇게 생각을 하게 됩니다.

‘인공지능은 인간과 다르게 편견이 존재하지 않아요.’ 이렇게들 이야기하죠?
하지만 개발자가 편견을 가진 사람이라면 그가 만든 인공지능도 편견을 가질 수밖에 없을 것입니다.
그래서 인공지능 개발자의 도덕성이 매우 매우 중요한 것입니다.
역시 다음 기사를 함께 읽어보도록 하겠습니다.


[3페이지 학습자료]

인공지능’은 지난 몇 년간 산업기술계를 넘어 사회에서 가장 주목받은 단어로, 사회 변화의 키워드였다.
심화신경망, 딥러닝, 기계학습, 은닉층… 기술용어가 일상어로 쓰였고 장밋빛 기대와 종말론적 우려가 충돌했다.

레이 커즈와일은 2045년이면 인공지능이 인류 전체 지능을 능가하는 초지능이 될 것이며, 스티븐 호킹과 일론 머스크 등은 인간을 위협할 슈퍼인공지능 개발을 멈춰야 한다고 목소리를 높여 왔다.
미국 라스베이거스의 소비자가전전시회(CES)에서 많은 제품이 인공지능을 홍보했고 사회의 높은 관심은 여전하지만, 인공지능 연구 일선에서는 차분한 목소리도 나오고 있다.

딥러닝을 개발한 공로로 튜링상을 받은 요수아 벤지오 캐나다 몬트리올대 교수는 지난 10년간 이해관계 있는 기업들에 의해서 인공지능의 능력이 과대포장되어 왔다고 말했다.
카티야 호프만 마이크로소프트연구소 수석연구원도 ‘인공지능이 새로운 국면으로 옮겨가고 있다고 생각한다며 벤지오에 동조했다.

인공지능은 마케팅 수단과 미래 기술담론으로 여전히 범람하지만, 연구 현실에서는 다른 모습들이 보고되고 있다.
2011년 미국의 퀴즈프로그램 제퍼디에서 인간 퀴즈 최고수들을 제압한 IBM의 인공지능 왓슨은 이후 국내외 대형 병원에 투입됐지만, 기대한 성과를 내지 못해 계약 연장이나 추가도입 사례가 드물다.

세계 최대의 인공지능 연구기업 딥마인드는 오락실 게임, 바둑, 스타크래프트, 포커, 단백질 구조 분석 등 영역에서 인간을 능가하는 사례를 잇따라 내놓으며 주목받았지만, 불안도 낳고 있다.


와이어드에 따르면, 딥마인드의 늘어나는 손실 규모는 기업의 지속가능성을 위협하고 있다.
2014년 구글에 인수된 딥마인드는 2016년 1억 5400만 달러, 2017년 3억 4100만 달러, 2018년 5억 7200만 달러 등 3년간 손실누적액이 10억 달러(약 1조2000억 원)를 넘어선다.
여기에 올 하반기 10억 달러의 부채가 추가될 예정이다.

미국의 인공지능 기업 어피니티의 최고경영자 지아 치슈티는 2018년 [파이낸셜 타임스] 기고를 통해 인공지능의 겨울이 오고 있다고 주장한 바 있다.
인공지능이 퀴즈나 바둑, 체스 등 좁은 영역에서 데이터 학습을 통해 패턴 발견엔 뛰어나지만, 현실의 복잡한 문제 해결에선 이렇다 할 실적이 없다.

치슈티는 전반적인 인공지능과 빅데이터에 대한 투자는 대부분 낭비이기 때문에 중단해야 한다고 주장했다.
2016년 이후 인공지능 분야에서 일어난 괄목할 연구 진전과 집중된 관심, 투자 자원은 인공지능의 세 번째 겨울은 오지 않을 것이라는 견해를 확산시켰다.
1956년 다트머스대 학술대회에서 인공지능이란 용어가 만들어진 뒤 인공지능은 긍정적 전망과 초라한 실적을 반복하며 1970년대와 80년대 두 차례 인공지능의 겨울로 불리는 침체기를 겪었다.

인공지능의 겨울은 연구, 투자, 자금 지원이 위축되는 시기를 일컫는 말이다.
컨설팅기업 가트너가 기술의 수용 과정을 도입, 과도한 기대, 거품 붕괴, 안정 단계로 설명하는 하이프곡선의 사례로 언급되기도 한다.
인공지능의 겨울은 연구의 실패 때문이라기보다 과도한 기대와 마케팅 영향이 크다.

인공지능 석학인 얀 르쿤 뉴욕대 교수는 인공지능은 사람들이 제공할 수 없는 일들을 요청했기 때문에 인공지능의 겨울을 겪었다고 말했다.
하지만 현재는 인공지능의 겨울을 말하기엔 성급하다는 견해가 지배적이다.

미국 국방부 등 일부 국가의 예산지원 여부에 큰 영향을 받던 과거와 달리 각국 정부가 앞다퉈 육성정책을 발표하고 있으며 중국과 미국은 이 분야 연구의 패권 다툼을 벌이고 있기 때문이다.
산업계와 자본의 투자도 넘쳐나고 있다.
알파고와 딥러닝이 인공지능에 대한 대중적 기대와 불안을 부풀린 만큼 제자리를 찾는 과정은 자연스러워 보인다.
그동안 부정확하고 포괄적인 마케팅 용어로 쓰였던 인공지능도 디지털화·컴퓨터화와 같은 구체 용어로 세분화할 필요도 있다.



이 기사를 읽으면서 여러분은 어떤 생각을 했습니까?

저는 두 가지를 생각해봤습니다.

첫 번째는 하이퍼 곡선으로 보는 인공지능의 미래.
IT 시장 조사 기관인 가트너는 신기술 시장과 기대, 성숙도를 나타내는 하이프 사이클을 매년 발표하고 있습니다.


가트너가 제시하는 하이프 사이클의 5단계는 다음과 같은데요.
그런 단계는 태동기, 거품기, 환멸의 시기, 재조명기 그리고 안정기로 구분이 되는데요.
각각의 단계별 특징에 대해서 설명을 드리겠습니다.

첫 번째는 태동기입니다.
새로운 혁신 기술이 태동되는 시기로 이 단계에서 상용화된 제품이 없이 사업적 가치가 증명되지 않습니다.
다만, 그런 기술을 개발하는 개발자들, 혁신적인 사람들이 그 기술이 가져다줄 새로운 효익, 혜택에 대해서 적극적으로 어필하면서 일반 대중과 시장이 그런 기술에 대해서 관심을 갖기 시작합니다.

두 번째는 거품기입니다.
이 거품기에서는 성공 사례보다 실패 사례가 많은 시기로서 이러한 기술이나 새로운 혁신 제품들을 얼리어답터만 구매할 뿐 일반 소비자에게는 아직은 생소한 기술이 대부분인데요.
이러한 혁신 기술이 새로운 기회를 가져다 줄 것으로 생각이 되면서 많은 기업들이 그런 기술을 기반으로 다양한 제품과 서비스를 만들어냅니다.

하지만 거품기에서 유추할 수 있듯이 이 단계에서는 성공사례보다 실패 사례가 점점 더 많아지면서 그 단계에서는 조금 문제가 되는 상황이 발생하는데요.

그것이 바로 환멸의 시기입니다.
환멸의 시기에는 대중들이 그런 기술에 대해서 실망하고 또 많은 기업들이 사업을 포기하는 단계로서 그런 혁신 기술에 대해서 기업과 대중의 관심이 점점 사라지는 시기이죠.
그런데 기술의 특징은요.

이런 환멸의 시기를 거쳐서 다시 한번 도약하는 재도약기를 반드시 가져오게 되어 있습니다.
왜냐하면 시장에서 불편해하는 다양한 문제점들을 기술 개발자들이 그리고 제품을 기획하는 사람들이 문제를 해결하기 시작하면서 기존보다 더 나은 기술, 기존보다 더 나은 제품과 서비스가 나오기 때문에 이런 어려움을 극복하고 다시 한번 도약하는 시기가 생기는데 이것이 바로 재조명기입니다.

이 재조명기에서는요.
기존에 많은 기업들 중에 실패를 경험하고 그 시장을 떠나지만 그럼에도 불구하고 그 시장에 남아서 묵묵하게 기술과 제품과 서비스를 연구하는 혁신가들 그리고 혁신적인 기업이 남아 있습니다.
그 기업들의 노력의 결과로 드디어 소비자들을 만족시킬 만한 만족스러운 제품과 서비스가 만들어지게 되는데요.
이를 통해 성공적인 수익 모델이 나타나는 시기가 바로 재조명기입니다.

즉, 소비자가 기술을 받아들이고 실생활 속에 그 기술이 녹아듦으로써 그 기술이 조금 더 긍정적인 부분으로 평가를 받는, 즉 재조명이 이루어지게 되죠.


이 태동기부터 재조명기까지 그 안에서 지속적인 노력을 했던 기업들은 선도 기업으로서 리더십을 가지게 됩니다.
많은 소비자들이 그 기술과 함께 그 기업을 연계시키면서 그런 제품에 대해서 오랫동안 그 시장에 남아 있던 기업들의 제품을 선택하게 돼요.
그런데 거품기와 환멸의 시기에서 쓴맛을 보고 나간 기업들이 ‘이것은 우리에게 노다지 땅이었는데 내가 이걸 몰라봤네.’ 그러면서 다시 들어가게 되면 그 시장에서 지속적으로 혁신 노력을 했던 선도 진입자보다 불리한 상황에 놓여지기 때문에 다시 시장에 참여한 기업들은 그만큼의 간극을 가져가고 선도 기업자들을 캐치 업하기가, 따라잡기가 상당히 힘든 상황이 되는 겁니다.

즉, 이 재조명기는 태동기부터 환멸의 시기를 지나서 묵묵하게 그런 혁신 노력을 기울인 기업들에 대한 혜택이, 보상이 이루어지는 시기로 볼 수 있겠죠?

그다음 단계는 안정기입니다.
이것은 시장이 기술을 본격적으로 수용하고 매출이 증대되는 시기로서 다양한 서비스가 출현하는데요.
그 시장에서 오랫동안 묵묵하게 노력했던 선도 진입자뿐만 아니라 재조명기에 빠르게 시장에 들어가서 빠른 속도로 캐치 업하는 그런 다양한 경쟁자들이 시장에서 경쟁을 하면서 소비자들은 조금 더 다양한 서비스와 제품 그런 제품과 서비스를 조금 더 낮은 가격으로 누릴 수 있게 되면서 충분한 시장이 형성되는 게 바로 안정기가 되겠습니다.


그렇다면 인공지능은 태동기, 거품기, 환멸의 시기, 재조명기, 안정기 중에 어느 단계에 진입한 상태일까요?
2019년도에 가트너가 제공한 하이프 곡선에 따르면 인공지능 관련 기술은 태동기를 지나서 거품기를 지나고 있는 상황입니다.

언젠가는 롤러코스터처럼 미끄러지는 시기가 올 거고 많은 기업이 인공지능 분야에서 퇴출될 텐데요.
그러나 지금까지 많은 혁신 기술들은 거품기와 환멸의 시기를 거쳐서 그 과정에서도 묵묵하게 기술을 발전시켜온 몇몇 기업에 의해 시장이 열리고 매출과 서비스 측면에서 큰 성과가 있었습니다.

우리가 지금은 아무 불편 없이 사용하는 무선 인터넷과 스마트폰도 다 이런 과정을 거쳐서 시장에 안정적으로 안착을 하고 있는데요.
이를 통해 볼 때 인공지능 분야도 대중의 실망과 비판, 기업들의 사업 실패에 직면할 것은 분명하나 그럼에도 불구하고 선도 기업들의 혁신 노력으로 큰 시장과 안정적인 서비스를 제공할 것으로 기대됩니다.


두 번째는 인공지능 기술은 기업의 미래 먹거리다, 라는 점입니다.
우리 수업에서 자주 언급된 구글, 엔비디아, 페이스북 등 공룡 기업들은 인공지능 플랫폼 생태계를 확장시켜서 그 안에서 영향력을 강화하고 있습니다.
IT 기업들뿐만이 아니라 일반 기업들도 데이터 중심의 경영이 기업 문화로 자리잡으면서 데이터 확보와 처리에 대한 요구가 증가하고 있고요.
이러한 요구는 인공지능을 발전시키는 원동력이 될 것으로 기대합니다.


셋째 고객들의 Pain Point가 무엇인지를 고민하라, 입니다.
Pain Point는 말 그대로 아픈 곳, 통점을 의미하는데요.
마케팅 분야에서는 충족되지 못한 소비자의 욕구, 소비자가 불편해하는 것을 의미합니다.
제 아무리 서비스가 혁신적이어도 고객이 불편해하는 문제를 해결하지 못한다면 환멸의 시기에 접어들게 될 것이므로 고객이 불편해하는 요소를 잘 파악해서 이를 해결하기 위한 노력을 기울여야 합니다.
2020년 미국의 클램슨대는 A사와 B사의 스마트 스피커용 음성 앱을 조사했는데 이들의 앱은 이용자의 개인 정보와 민감 정보를 수집하면서도 어떤 데이터를 수집하는지 명확히 밝히지 않고 있다는 것을 밝혀냈으며 이용자 몰래 정보를 수집하는 기술을 발견하기도 했습니다.


이런 뉴스가 퍼지면 사람들은 인공지능 스피커를 사용하지 않으려 하겠죠?
인공지능 스피커의 가장 큰 장점은 타이핑이 아닌 말로 명령을 할 수 있다는 건데 인공지능에게 원하는 답을 얻기 위해서는 기계처럼 대화를 해야 한다는 문제가 있습니다.

즉, 기술이 사람에게 맞춰주는 것이 아닌 사람이 기술에게 맞춰지고 있는 이 아이러니한 상황은 구매한 인공지능 스피커를 값비싼 MP3로 전락시키고 있습니다.

어떤 연구에 따르면 음성 정보를 검색할 때 소비자가 느끼는 Pain Point는 다음과 같이 조사된 바 있습니다.

중간값이 4점인 것을 고려하면서 한번 보시기 바랍니다.

먼저 멀리 떨어져 있거나 다른 소리와 섞이면 음성 인식을 못한다는 부분에 대해서 소비자들은 4.87만큼의 불편함을 느꼈고요.
사람을 부르는 소리, TV 소리 등을 wake-up으로 인식하는 경우를 4.84로 봤습니다.
TV를 틀었는데 TV에서 나오는 소리 때문에 갑자기 인공지능이 스스로가 이렇게 로그인이 되는 거죠.
나는 인공지능 스피커를 켤 생각이 없는데 내가 다른 사람을 불렀더니 인공지능 스피커가 알아서 켜졌다, 이런 것도 불편함이라는 겁니다.
사람을 부르는 소리, TV 소리 등을 질의나 요청으로 인식한 경우가 4.87이었습니다.
이럴 수도 있겠어요.

내가 인공지능 스피커를 켜놨는데 홈쇼핑 채널을 제가 틀었습니다.
그런데 거기에서 ‘주문하세요. 이렇게 싼 가격이 없습니다. 주문하세요.’라고 할 때 이 ‘주문하세요.’라고 말하는 호스트의 목소리를 사용자의 목소리로 혼동을 해서 이 사용자의 의도와는 다르게 그 제품을 구매, 주문을 했다면 그런 문제가 발생할 수 있겠죠?

실제로 이런 부분은 미국에서 많이 발생하고 있는 문제라고 합니다.
그리고 내가 질문한 부분에 대해서 답변 지연은 4.58, 질의나 요청 사항을 잘못 이해해서 잘못된 답변을 한 경우가 5.0, 추가 질의를 할 때 기존 대화의 문맥에 따라 답변을 못하는 경우가 4.87로 나타났습니다.
중간값이 4점인데 이런 부분에 대해서는 4점 이상, 즉 대부분의 소비자들이 불편함을 느끼는 것으로 나타났는데 이런 문제의 원인을 분석해보면 음성 인식의 성능 문제로 귀결이 된다는 점을 알 수 있습니다.
따라서 이런 문제를 해결하기 위해서는 신호 인식 및 분석에 대한 기술 개선이 요구된다.
즉, 비즈니스 모델의 문제라기보다는 기술이 갖고 있는 한계의 문제다.
이런 문제를 기술적으로 해결하기 위한 노력을 해야 하겠다.
그런 시사점을 얻을 수 있겠습니다.

RoboAdvisor는 개인의 투자 성향을 분석한 후에 최적화된 포트폴리오를 제안하고 시장 상황에 따라 이를 재구성해서 운영해주는 온라인 자산 관리 서비스입니다.
인공지능 알고리즘과 빅데이터에 기반해서 보다 정확하고 자동화된 투자자문서비스를 제공하는데요.
이를 위해 사용자가 투자 성향을 파악하기 위한 질문에 답변을 하면 투자자의 인구 통계학적 특성과 투자 성향을 파악해서 고객에게 적합한 포트폴리오를 제안하는 것이 바로 RoboAdvisor가 작동하는 방식입니다.

그런데 이때 고객에게 너무 많은 선택권이 주어지면 고객이 정확하게 판단하지 못하거나 선택 자체를 힘들어할 수 있기 때문에 이 부분이 바로 고객에게는 pain point가 될 수 있습니다.
‘내가 선택해야 하는 옵션 7개나 되는데 이런 각각의 포트폴리오의 특장점이 뭔지 모르겠어.’ 이런 것들을 고민하다가 아예 그 플랫폼을, 사이트를 빠져나갈 수도 있다는 거죠.
많은 사람이 스스로 판단을 못하는 그런 특징이 있거든요.

저조차도 인터넷 쇼핑몰에서 제가 보게 되는 옵션이 많아지면 그냥 스스로가 판단하지 못하고 10분, 20분을 옷을 봐놓고도 결국 의사 결정을 하지 못해서 사이트를 빠져나오는 경우가 많은데 이러한 고객의 pain point는 고객에게 불편함으로 다가가게 되고 이를 통해 RoboAdvisor는 고객들이 외면하는 서비스가 될 수 있다는 겁니다.
이런 문제가 발생한 이유는 추천의 정확성만 고려했을 뿐 사용자의 고충은 고려하지 않았기 때문일 겁니다.
인공지능이 환멸의 시기에 놓여 있는 이 시기를 짧게 가져가기 위해서 우리는 고객의 pain point에 집중해야 되겠습니다.
